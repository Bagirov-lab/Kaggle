{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read Before","metadata":{}},{"cell_type":"markdown","source":"- https://www.kaggle.com/code/raddar/icr-competition-analysis-and-findings/notebook\n- https://www.tensorflow.org/guide/core/logistic_regression_core\n- https://www.kaggle.com/code/muelsamu/simple-tabpfn-approach-for-score-of-15-in-1-min/notebook - good example how to add TabPFN\n- https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Metric - good guide on creating custom metric in Keras\n- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/410139 - overall notes about similar competitions","metadata":{}},{"cell_type":"markdown","source":"Plan:\n- [x] Feature Engineering (1 day)\n- [x] CV and Model Selection (1 day)\n- [x] Validation (1 day)\n- [x] Review\n- [x] Make Artefacts -> Made Utility script for WoE\n- [x] Solve Error With Solution -> Made If new catgory then choose worst WoEs (Can make two splits woth worst and other value )\n- [x] Add TabPFN (Added Private Sample with package files) and No CV TabPFN preds\n- [x] Added Weighted Submition with respect to Competion Metric Mean\n- [x] Refactor More Accurately train RF part & Make Dev branch for Git\n- [x] Experiment with GadientClassifier and Parameters ( Tried GadientClassifier / Added Better displayed TOC )\n- [x] CV TabPFN - looks even inferior to GBT. May be due to preprosessing.\n- [x] Ensembled into Submition results from several Classifiers (There is aa room for Playing with manually assigned weights)\n- [x] Due to time consideration -> SUBMITION: bool\n- [x] Submition Error When calculating results.\n- [x] Rethink CV (check dimension) v31->v32,\n- [x] Solve problem with accuracy (showns NaNs) -> Changed to Binary Accuracy version\n- [x] Solved problem with NaNs in metric -> min/max vals less than 1 more than 0, as in competrion calculator\n- [x] loss: 0.0000e+00. Why ? Is it OK ? -> Yes it is okey. https://discuss.tensorflow.org/t/tfdf-custom-loss/2223\n- [ ] Research wheather it is possible to train with respect to Gradient of the metric.\n- [ ] Found that some variables are constant as they represent some features for categroical column which takes only two values, so makes sense to drop them in order not overtrain. I will make split -> make two versions of model which is run if Group A (on all data), which is Group B ( which finetuned after )\n- [ ] Ensemble Results by some model:\n    - Currently Simple Manual Weights, which may be more optimal. Need to make some grid and choose the best.\n    - I use Mean for Each CV Branch, may-be also grant some threshs or weights\n    - [x] Refactored each Model Estimation to result into Train/Valid/Test Frames\n- [ ] Cutoffs\n    - https://medium.com/swlh/determining-a-cut-off-or-threshold-when-working-with-a-binary-dependent-target-variable-7c2342cf2a7c\n    - Find Lower/Upper Bounds which maximises competition metric\n- [ ] May be try several CVs\n- [ ] May be play with uplift to lessen features input\n    ","metadata":{}},{"cell_type":"code","source":"SUBMITION = False","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:44:18.923740Z","iopub.execute_input":"2023-07-28T18:44:18.924161Z","iopub.status.idle":"2023-07-28T18:44:18.955874Z","shell.execute_reply.started":"2023-07-28T18:44:18.924128Z","shell.execute_reply":"2023-07-28T18:44:18.954981Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install TabPFN offline","metadata":{}},{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr\n\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n\n!cp /kaggle/input/pip-packages-icr/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:44:18.960627Z","iopub.execute_input":"2023-07-28T18:44:18.960990Z","iopub.status.idle":"2023-07-28T18:44:34.787705Z","shell.execute_reply.started":"2023-07-28T18:44:18.960961Z","shell.execute_reply":"2023-07-28T18:44:34.786159Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/pip-packages-icr\nProcessing /kaggle/input/pip-packages-icr/tabpfn-0.1.9-py3-none-any.whl\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.23.5)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (5.4.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.28.2)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.2.2)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.0.0+cpu)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2023.5.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\nInstalling collected packages: tabpfn\nSuccessfully installed tabpfn-0.1.9\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Utils","metadata":{}},{"cell_type":"code","source":"from woe_utils import WOENumericalComplex","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:44:34.790258Z","iopub.execute_input":"2023-07-28T18:44:34.790732Z","iopub.status.idle":"2023-07-28T18:44:35.777433Z","shell.execute_reply.started":"2023-07-28T18:44:34.790684Z","shell.execute_reply":"2023-07-28T18:44:35.776605Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Import Standard Libs","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nfrom keras import metrics # accuracy\nfrom keras import backend as K\n\nimport keras_tuner as kt\n\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import log_loss,accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom tabpfn import TabPFNClassifier\n\nimport warnings\nfrom tqdm.notebook import tqdm\n\nimport joblib\nimport os\nimport shutil\n\npd.set_option('display.max_rows', 500)\nwarnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T20:19:08.879847Z","iopub.execute_input":"2023-07-28T20:19:08.880250Z","iopub.status.idle":"2023-07-28T20:19:08.887731Z","shell.execute_reply.started":"2023-07-28T20:19:08.880219Z","shell.execute_reply":"2023-07-28T20:19:08.886912Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Load the Dataset","metadata":{}},{"cell_type":"code","source":"dataset_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv', index_col='Id')\ndataset_df.columns = dataset_df.columns.str.rstrip()\nprint(\"Full train dataset shape is {}\".format(dataset_df.shape))\n\ndataset_test_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv', index_col='Id')\ndataset_test_df.columns = dataset_test_df.columns.str.rstrip()\nprint(\"Full test dataset shape is {}\".format(dataset_test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:44:47.927058Z","iopub.execute_input":"2023-07-28T18:44:47.928222Z","iopub.status.idle":"2023-07-28T18:44:47.978583Z","shell.execute_reply.started":"2023-07-28T18:44:47.928185Z","shell.execute_reply":"2023-07-28T18:44:47.977360Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Full train dataset shape is (617, 57)\nFull test dataset shape is (5, 56)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Compute Basic Info","metadata":{}},{"cell_type":"code","source":"mining_columns: list = [i for i in dataset_df.columns if i not in [\"Id\",\"Class\"]]\n\ndef compute_basic_stats(columns: list, df: pd.DataFrame) -> pd.DataFrame:\n    \n    out: dict = {}\n    \n    for i in tqdm(columns):\n        mask = df[i].notna()\n        \n        out[i] = {'nunique':df[i].nunique(),\n                  'na_share':round(100*df[i].isna().sum()/df[i].count(),1),\n                  'dtype':df[i].dtype\n                 }\n        if is_numeric_dtype(df[i]):\n            out[i]['correlation'] = round(np.corrcoef(x=df.loc[mask,i],y=df.loc[mask,'Class'])[0,1],2)\n            out[i]['min'] = df.loc[mask,i].min()\n            out[i]['max'] = df.loc[mask,i].max()\n            out[i]['std'] = df.loc[mask,i].std()\n            out[i]['mean'] = df.loc[mask,i].mean()\n            i_lorreg = LogisticRegression()\n            X = df.loc[mask,i].values.reshape(-1,1)\n            y = df.loc[mask,'Class'].values\n            i_lorreg.fit(X=X, y=y)\n            y_pred = i_lorreg.predict(X)\n            out[i]['logloss'] = log_loss(y_true=y, y_pred=y_pred)\n            \n            \n    out = pd.DataFrame(out).T\n    \n    out = out.sort_values('logloss',ascending=True)\n    \n    return out\n\n# Train\nbasic_stats_1 = compute_basic_stats(columns=mining_columns, df=dataset_df)\n\n# Inference\nbasic_stats_1.to_pickle('/kaggle/working/basic_stats_1.pickle')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:50:00.298578Z","iopub.execute_input":"2023-07-28T18:50:00.299005Z","iopub.status.idle":"2023-07-28T18:50:00.773756Z","shell.execute_reply.started":"2023-07-28T18:50:00.298970Z","shell.execute_reply":"2023-07-28T18:50:00.772753Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/56 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"884104abda6741cf86e025b1eab154d6"}},"metadata":{}}]},{"cell_type":"code","source":"basic_stats_1","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:50:02.762922Z","iopub.execute_input":"2023-07-28T18:50:02.763318Z","iopub.status.idle":"2023-07-28T18:50:02.786932Z","shell.execute_reply.started":"2023-07-28T18:50:02.763286Z","shell.execute_reply":"2023-07-28T18:50:02.785840Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   nunique na_share    dtype correlation          min          max  \\\nDU     253      0.2  float64        0.26     0.005518   161.355315   \nBC     259      0.0  float64        0.16       1.2299  1463.693448   \nAF     599      0.0  float64         0.3    192.59328  28688.18766   \nEH     127      0.0  float64        0.18     0.003042    42.569748   \nAM     605      0.0  float64        0.24     3.177522    630.51823   \nFD     337      0.0  float64        0.13      0.29685  1578.654237   \nDI     571      0.0  float64        0.26     60.23247  1049.168078   \nFR     435      0.0  float64         0.1      0.49706   1244.22702   \nAB     217      0.0  float64        0.28     0.081187     6.161666   \nCF     586      0.0  float64        0.11     0.510888   200.967526   \nBZ     115      0.0  float64        0.11   257.432377   50092.4593   \nFE     615      0.0  float64        0.22  1563.136688  143224.6823   \nAX     427      0.0  float64         0.1     0.699861     38.27088   \nBR     566      0.0  float64        0.09    51.216883  179250.2529   \nGB     560      0.0  float64        0.08     4.102182   135.781294   \nAY     148      0.0  float64        0.08     0.025578    10.315851   \nFC     600      0.2  float64        0.03     7.534128  3030.655824   \nFS     161      0.3  float64         0.0      0.06773    31.365763   \nCC     602      0.5  float64       -0.05     0.176874     4.103032   \nGH     596      0.0  float64        0.03     9.432735    81.210825   \nDV      39      0.0  float64        0.02      1.74307     25.19293   \nDY     590      0.0  float64        0.06     0.804068   152.355164   \nEE     513      0.0  float64       -0.14     0.286201    18.324926   \nGE     264      0.0  float64       -0.07    72.611063  1497.351958   \nAH     227      0.0  float64        0.04    85.200147  1910.123198   \nDN     576      0.0  float64       -0.01     6.339496    62.808096   \nEP     275      0.0  float64       -0.07    78.526968  1063.594578   \nEU     455      0.0  float64       -0.04     3.828384   6501.26448   \nEG     610      0.0  float64       -0.02     185.5941  30243.75878   \nFI     498      0.0  float64       -0.09      3.58345    35.851039   \nDH     191      0.0  float64       -0.21     0.040995     1.060404   \nGF     611      0.0  float64       -0.13    13.038894  143790.0712   \nGI     615      0.0  float64        0.08     0.897628   191.194764   \nDE     616      0.0  float64       -0.12    35.998895   2103.40519   \nDA     611      0.0  float64        -0.2       6.9064    210.33092   \nCW     426      0.0  float64       -0.06      7.03064    64.521624   \nCU     307      0.0  float64       -0.08     0.137925     4.951507   \nAZ     484      0.0  float64        0.01     3.396778    38.971568   \nCL     123      0.0  float64        0.02     1.050225    31.688153   \nCH     135      0.0  float64        0.01     0.003184     0.224074   \nBD     617      0.0  float64        0.11   1693.62432  53060.59924   \nBN      53      0.0  float64         0.2       9.8868      29.3073   \nDL     604      0.0  float64       -0.15      10.3456     326.2362   \nCS     576      0.0  float64       -0.05    13.784111   267.942823   \nFL     388      0.2  float64        0.24     0.173229   137.932739   \nGL     355      0.2  float64       -0.12     0.001129       21.978   \nCB     553      0.3  float64       -0.01     12.49976  2271.436167   \nDF     137      0.0  float64        0.06      0.23868    37.895013   \nBP     612      0.0  float64        0.16    72.948951   2447.81055   \nEB     439      0.0  float64        0.09     4.926396     94.95858   \nAR     130      0.0  float64        0.06     8.138688   178.943634   \nCD     584      0.0  float64        0.17      23.3876   633.534408   \nEL     311     10.8  float64        0.07     5.394675   109.125159   \nCR     595      0.0  float64       -0.23     0.069225     3.039675   \nBQ     515     10.8  float64        0.28     1.331155   344.644105   \nEJ       2      0.0   object         NaN          NaN          NaN   \n\n             std          mean   logloss  \nDU      9.034721        1.8029   5.55868  \nBC     65.166943      8.053012  5.724924  \nAF   2300.322717   3502.013221  5.900177  \nEH      1.847499      0.305107  5.900177  \nAM     69.728226     38.968552  5.900177  \nFD     64.754262      6.930086  5.900177  \nDI     86.084419    146.972099  5.900177  \nFR     50.181948      3.533905  5.900177  \nAB      0.468388      0.477149  6.017012  \nCF     13.571133     11.241064  6.192265  \nBZ   2076.371275    550.632525  6.192265  \nFE  11331.294051  10306.810737  6.192265  \nAX      2.551696      5.545576  6.250682  \nBR   7575.293707   1218.133238  6.250682  \nGB      9.991907     20.724856  6.250682  \nAY      0.416817       0.06032  6.250682  \nFC    165.551545     71.341526  6.260829  \nFS      1.305365      0.421501   6.27101  \nCC      0.263994      0.688801  6.281223  \nGH      9.864239     31.489716    6.3091  \nDV      1.484555       1.92483    6.3091  \nDY     18.116679     26.388989    6.3091  \nEE      2.058344      3.064778    6.3091  \nGE    144.181524    131.714987    6.3091  \nAH     127.83895    118.624513    6.3091  \nDN      8.038825     26.370568    6.3091  \nEP      68.44562    105.060712    6.3091  \nEU    390.187057     69.117005    6.3091  \nEG   1790.227476   1731.248215    6.3091  \nFI      2.934025     10.111079    6.3091  \nDH      0.112989      0.367002    6.3091  \nGF  19352.959387  14679.595398    6.3091  \nGI     36.266251     50.584437    6.3091  \nDE    317.745623    401.901299    6.3091  \nDA     21.210888     51.128326    6.3091  \nCW     14.645993     27.165653    6.3091  \nCU      0.538717      1.383792    6.3091  \nAZ      4.350645     10.566447    6.3091  \nCL       1.92221      1.403761    6.3091  \nCH      0.014808      0.030615    6.3091  \nBD   3021.326641   5350.388655    6.3091  \nBN      3.478278     21.419492    6.3091  \nDL     28.243187     94.795377    6.3091  \nCS     17.266347      36.91759    6.3091  \nFL     11.496257      5.433199  6.319342  \nGL      10.32701      8.530961  6.319342  \nCB    159.049302     77.104151  6.329617  \nDF      1.912384      0.633884  6.367517  \nBP    183.992505    231.322223  6.367517  \nEB      6.200281        9.0727  6.425935  \nAR     10.518877     10.128242  6.425935  \nCD      51.58513     90.251735  6.425935  \nEL     38.555707     69.582596  6.600454  \nCR      0.281195      0.742262  6.601188  \nBQ     96.479371     98.328737  7.053426  \nEJ           NaN           NaN       NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nunique</th>\n      <th>na_share</th>\n      <th>dtype</th>\n      <th>correlation</th>\n      <th>min</th>\n      <th>max</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>logloss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DU</th>\n      <td>253</td>\n      <td>0.2</td>\n      <td>float64</td>\n      <td>0.26</td>\n      <td>0.005518</td>\n      <td>161.355315</td>\n      <td>9.034721</td>\n      <td>1.8029</td>\n      <td>5.55868</td>\n    </tr>\n    <tr>\n      <th>BC</th>\n      <td>259</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.16</td>\n      <td>1.2299</td>\n      <td>1463.693448</td>\n      <td>65.166943</td>\n      <td>8.053012</td>\n      <td>5.724924</td>\n    </tr>\n    <tr>\n      <th>AF</th>\n      <td>599</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.3</td>\n      <td>192.59328</td>\n      <td>28688.18766</td>\n      <td>2300.322717</td>\n      <td>3502.013221</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>EH</th>\n      <td>127</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.18</td>\n      <td>0.003042</td>\n      <td>42.569748</td>\n      <td>1.847499</td>\n      <td>0.305107</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>AM</th>\n      <td>605</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.24</td>\n      <td>3.177522</td>\n      <td>630.51823</td>\n      <td>69.728226</td>\n      <td>38.968552</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>FD</th>\n      <td>337</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.13</td>\n      <td>0.29685</td>\n      <td>1578.654237</td>\n      <td>64.754262</td>\n      <td>6.930086</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>DI</th>\n      <td>571</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.26</td>\n      <td>60.23247</td>\n      <td>1049.168078</td>\n      <td>86.084419</td>\n      <td>146.972099</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>FR</th>\n      <td>435</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.1</td>\n      <td>0.49706</td>\n      <td>1244.22702</td>\n      <td>50.181948</td>\n      <td>3.533905</td>\n      <td>5.900177</td>\n    </tr>\n    <tr>\n      <th>AB</th>\n      <td>217</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.28</td>\n      <td>0.081187</td>\n      <td>6.161666</td>\n      <td>0.468388</td>\n      <td>0.477149</td>\n      <td>6.017012</td>\n    </tr>\n    <tr>\n      <th>CF</th>\n      <td>586</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.11</td>\n      <td>0.510888</td>\n      <td>200.967526</td>\n      <td>13.571133</td>\n      <td>11.241064</td>\n      <td>6.192265</td>\n    </tr>\n    <tr>\n      <th>BZ</th>\n      <td>115</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.11</td>\n      <td>257.432377</td>\n      <td>50092.4593</td>\n      <td>2076.371275</td>\n      <td>550.632525</td>\n      <td>6.192265</td>\n    </tr>\n    <tr>\n      <th>FE</th>\n      <td>615</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.22</td>\n      <td>1563.136688</td>\n      <td>143224.6823</td>\n      <td>11331.294051</td>\n      <td>10306.810737</td>\n      <td>6.192265</td>\n    </tr>\n    <tr>\n      <th>AX</th>\n      <td>427</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.1</td>\n      <td>0.699861</td>\n      <td>38.27088</td>\n      <td>2.551696</td>\n      <td>5.545576</td>\n      <td>6.250682</td>\n    </tr>\n    <tr>\n      <th>BR</th>\n      <td>566</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.09</td>\n      <td>51.216883</td>\n      <td>179250.2529</td>\n      <td>7575.293707</td>\n      <td>1218.133238</td>\n      <td>6.250682</td>\n    </tr>\n    <tr>\n      <th>GB</th>\n      <td>560</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.08</td>\n      <td>4.102182</td>\n      <td>135.781294</td>\n      <td>9.991907</td>\n      <td>20.724856</td>\n      <td>6.250682</td>\n    </tr>\n    <tr>\n      <th>AY</th>\n      <td>148</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.08</td>\n      <td>0.025578</td>\n      <td>10.315851</td>\n      <td>0.416817</td>\n      <td>0.06032</td>\n      <td>6.250682</td>\n    </tr>\n    <tr>\n      <th>FC</th>\n      <td>600</td>\n      <td>0.2</td>\n      <td>float64</td>\n      <td>0.03</td>\n      <td>7.534128</td>\n      <td>3030.655824</td>\n      <td>165.551545</td>\n      <td>71.341526</td>\n      <td>6.260829</td>\n    </tr>\n    <tr>\n      <th>FS</th>\n      <td>161</td>\n      <td>0.3</td>\n      <td>float64</td>\n      <td>0.0</td>\n      <td>0.06773</td>\n      <td>31.365763</td>\n      <td>1.305365</td>\n      <td>0.421501</td>\n      <td>6.27101</td>\n    </tr>\n    <tr>\n      <th>CC</th>\n      <td>602</td>\n      <td>0.5</td>\n      <td>float64</td>\n      <td>-0.05</td>\n      <td>0.176874</td>\n      <td>4.103032</td>\n      <td>0.263994</td>\n      <td>0.688801</td>\n      <td>6.281223</td>\n    </tr>\n    <tr>\n      <th>GH</th>\n      <td>596</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.03</td>\n      <td>9.432735</td>\n      <td>81.210825</td>\n      <td>9.864239</td>\n      <td>31.489716</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DV</th>\n      <td>39</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.02</td>\n      <td>1.74307</td>\n      <td>25.19293</td>\n      <td>1.484555</td>\n      <td>1.92483</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DY</th>\n      <td>590</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.06</td>\n      <td>0.804068</td>\n      <td>152.355164</td>\n      <td>18.116679</td>\n      <td>26.388989</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>EE</th>\n      <td>513</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.14</td>\n      <td>0.286201</td>\n      <td>18.324926</td>\n      <td>2.058344</td>\n      <td>3.064778</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>GE</th>\n      <td>264</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.07</td>\n      <td>72.611063</td>\n      <td>1497.351958</td>\n      <td>144.181524</td>\n      <td>131.714987</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>AH</th>\n      <td>227</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.04</td>\n      <td>85.200147</td>\n      <td>1910.123198</td>\n      <td>127.83895</td>\n      <td>118.624513</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DN</th>\n      <td>576</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.01</td>\n      <td>6.339496</td>\n      <td>62.808096</td>\n      <td>8.038825</td>\n      <td>26.370568</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>EP</th>\n      <td>275</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.07</td>\n      <td>78.526968</td>\n      <td>1063.594578</td>\n      <td>68.44562</td>\n      <td>105.060712</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>EU</th>\n      <td>455</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.04</td>\n      <td>3.828384</td>\n      <td>6501.26448</td>\n      <td>390.187057</td>\n      <td>69.117005</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>EG</th>\n      <td>610</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.02</td>\n      <td>185.5941</td>\n      <td>30243.75878</td>\n      <td>1790.227476</td>\n      <td>1731.248215</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>FI</th>\n      <td>498</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.09</td>\n      <td>3.58345</td>\n      <td>35.851039</td>\n      <td>2.934025</td>\n      <td>10.111079</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DH</th>\n      <td>191</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.21</td>\n      <td>0.040995</td>\n      <td>1.060404</td>\n      <td>0.112989</td>\n      <td>0.367002</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>GF</th>\n      <td>611</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.13</td>\n      <td>13.038894</td>\n      <td>143790.0712</td>\n      <td>19352.959387</td>\n      <td>14679.595398</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>GI</th>\n      <td>615</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.08</td>\n      <td>0.897628</td>\n      <td>191.194764</td>\n      <td>36.266251</td>\n      <td>50.584437</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DE</th>\n      <td>616</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.12</td>\n      <td>35.998895</td>\n      <td>2103.40519</td>\n      <td>317.745623</td>\n      <td>401.901299</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DA</th>\n      <td>611</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.2</td>\n      <td>6.9064</td>\n      <td>210.33092</td>\n      <td>21.210888</td>\n      <td>51.128326</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>CW</th>\n      <td>426</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.06</td>\n      <td>7.03064</td>\n      <td>64.521624</td>\n      <td>14.645993</td>\n      <td>27.165653</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>CU</th>\n      <td>307</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.08</td>\n      <td>0.137925</td>\n      <td>4.951507</td>\n      <td>0.538717</td>\n      <td>1.383792</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>AZ</th>\n      <td>484</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.01</td>\n      <td>3.396778</td>\n      <td>38.971568</td>\n      <td>4.350645</td>\n      <td>10.566447</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>CL</th>\n      <td>123</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.02</td>\n      <td>1.050225</td>\n      <td>31.688153</td>\n      <td>1.92221</td>\n      <td>1.403761</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>CH</th>\n      <td>135</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.01</td>\n      <td>0.003184</td>\n      <td>0.224074</td>\n      <td>0.014808</td>\n      <td>0.030615</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>BD</th>\n      <td>617</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.11</td>\n      <td>1693.62432</td>\n      <td>53060.59924</td>\n      <td>3021.326641</td>\n      <td>5350.388655</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>BN</th>\n      <td>53</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.2</td>\n      <td>9.8868</td>\n      <td>29.3073</td>\n      <td>3.478278</td>\n      <td>21.419492</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>DL</th>\n      <td>604</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.15</td>\n      <td>10.3456</td>\n      <td>326.2362</td>\n      <td>28.243187</td>\n      <td>94.795377</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>CS</th>\n      <td>576</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.05</td>\n      <td>13.784111</td>\n      <td>267.942823</td>\n      <td>17.266347</td>\n      <td>36.91759</td>\n      <td>6.3091</td>\n    </tr>\n    <tr>\n      <th>FL</th>\n      <td>388</td>\n      <td>0.2</td>\n      <td>float64</td>\n      <td>0.24</td>\n      <td>0.173229</td>\n      <td>137.932739</td>\n      <td>11.496257</td>\n      <td>5.433199</td>\n      <td>6.319342</td>\n    </tr>\n    <tr>\n      <th>GL</th>\n      <td>355</td>\n      <td>0.2</td>\n      <td>float64</td>\n      <td>-0.12</td>\n      <td>0.001129</td>\n      <td>21.978</td>\n      <td>10.32701</td>\n      <td>8.530961</td>\n      <td>6.319342</td>\n    </tr>\n    <tr>\n      <th>CB</th>\n      <td>553</td>\n      <td>0.3</td>\n      <td>float64</td>\n      <td>-0.01</td>\n      <td>12.49976</td>\n      <td>2271.436167</td>\n      <td>159.049302</td>\n      <td>77.104151</td>\n      <td>6.329617</td>\n    </tr>\n    <tr>\n      <th>DF</th>\n      <td>137</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.06</td>\n      <td>0.23868</td>\n      <td>37.895013</td>\n      <td>1.912384</td>\n      <td>0.633884</td>\n      <td>6.367517</td>\n    </tr>\n    <tr>\n      <th>BP</th>\n      <td>612</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.16</td>\n      <td>72.948951</td>\n      <td>2447.81055</td>\n      <td>183.992505</td>\n      <td>231.322223</td>\n      <td>6.367517</td>\n    </tr>\n    <tr>\n      <th>EB</th>\n      <td>439</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.09</td>\n      <td>4.926396</td>\n      <td>94.95858</td>\n      <td>6.200281</td>\n      <td>9.0727</td>\n      <td>6.425935</td>\n    </tr>\n    <tr>\n      <th>AR</th>\n      <td>130</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.06</td>\n      <td>8.138688</td>\n      <td>178.943634</td>\n      <td>10.518877</td>\n      <td>10.128242</td>\n      <td>6.425935</td>\n    </tr>\n    <tr>\n      <th>CD</th>\n      <td>584</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>0.17</td>\n      <td>23.3876</td>\n      <td>633.534408</td>\n      <td>51.58513</td>\n      <td>90.251735</td>\n      <td>6.425935</td>\n    </tr>\n    <tr>\n      <th>EL</th>\n      <td>311</td>\n      <td>10.8</td>\n      <td>float64</td>\n      <td>0.07</td>\n      <td>5.394675</td>\n      <td>109.125159</td>\n      <td>38.555707</td>\n      <td>69.582596</td>\n      <td>6.600454</td>\n    </tr>\n    <tr>\n      <th>CR</th>\n      <td>595</td>\n      <td>0.0</td>\n      <td>float64</td>\n      <td>-0.23</td>\n      <td>0.069225</td>\n      <td>3.039675</td>\n      <td>0.281195</td>\n      <td>0.742262</td>\n      <td>6.601188</td>\n    </tr>\n    <tr>\n      <th>BQ</th>\n      <td>515</td>\n      <td>10.8</td>\n      <td>float64</td>\n      <td>0.28</td>\n      <td>1.331155</td>\n      <td>344.644105</td>\n      <td>96.479371</td>\n      <td>98.328737</td>\n      <td>7.053426</td>\n    </tr>\n    <tr>\n      <th>EJ</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"* Only one variable looks constrant over the target -> better to omit it.\n* Realised Better to add LogLoss metric for each feature -> loggloss\n","metadata":{}},{"cell_type":"markdown","source":"# Create Features","metadata":{}},{"cell_type":"code","source":"WoE_Columns = ['DU', 'BC', 'AF', 'EH', 'AM', 'FD', 'DI', 'FR', 'AB', 'CF', 'BZ', 'FE', 'AX', 'BR',\n               'GB', 'AY', 'FC', 'FS', 'CC', 'GH', 'DV', 'DY', 'EE', 'GE', 'AH', 'DN', 'EP', 'EU',\n               'EG', 'FI', 'DH', 'GF', 'GI', 'DE', 'DA', 'CW', 'CU', 'AZ', 'CL', 'CH', 'BD', 'BN',\n               'DL', 'CS', 'FL', 'GL', 'CB', 'DF', 'BP', 'EB', 'AR', 'CD', 'EL', 'CR', 'BQ']","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:50:11.931489Z","iopub.execute_input":"2023-07-28T18:50:11.931914Z","iopub.status.idle":"2023-07-28T18:50:11.938257Z","shell.execute_reply.started":"2023-07-28T18:50:11.931865Z","shell.execute_reply":"2023-07-28T18:50:11.937219Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def preprocess_train(train: pd.DataFrame, numeric_features: list, save_path: str) -> None:\n    woes = dict()\n    \n    # Make WoE Columns\n    for i in tqdm(numeric_features, 'WoE Encoding: '):\n        tmp_woe = WOENumericalComplex()\n        tmp_woe.fit(x=train[i], y=train['Class'])\n        woes[i] = tmp_woe\n    \n    # Save WoE\n    _ = joblib.dump(value=woes, filename=save_path)\n    print('Saved features: ', save_path)\n    \n    return None\n\ndef preprocess_inference(train: pd.DataFrame, test: pd.DataFrame, \n                         numeric_features: list,\n                         stats: pd.DataFrame, save_path: str) -> (pd.DataFrame, pd.DataFrame, list):\n    info = dict()\n    train_out = train.copy()\n    test_out = test.copy()\n    \n    out_features = list()\n    \n    # Make WoE Columns\n    woes = joblib.load(save_path)\n    \n    for i in tqdm(numeric_features, 'WoE Encoding: '):\n        train_out[i + '_WoE'] = woes[i].transform(X=train_out[i])\n        test_out[i + '_WoE'] = woes[i].transform(X=test_out[i])\n        out_features.append(i + '_WoE')\n    \n    # Make NA columns\n    for i in tqdm(['DU', 'FC', 'FS', 'CC', 'FL', 'GL', 'CB', 'EL', 'BQ'], 'Split by NA: '):\n        train_out[i+'_na'] = np.where(train_out[i].isna(),1,0)\n        test_out[i+'_na'] = np.where(test_out[i].isna(),1,0)\n        out_features.append(i + '_na')\n    \n    # Basic Logic -> normalise\n    for i in tqdm(numeric_features,'Normalise Numeric: '):\n        if stats.loc[i,'correlation'] > 0:\n            na_value = stats.loc[i,'max']\n        else:\n            na_value = stats.loc[i,'min']\n\n        train_out[i] = train_out[i].fillna(na_value)\n        test_out[i] = test_out[i].fillna(na_value)\n\n        train_out[i] = (train_out[i]-stats.loc[i,'mean'])/stats.loc[i,'std']\n        test_out[i] = (test_out[i]-stats.loc[i,'mean'])/stats.loc[i,'std']\n\n        out_features.append(i)\n            \n            \n    # Addition EJ -> has only two values, so if EJ == 'A'\n    train_out['EJ' + '_A'] = np.where(train_out['EJ'] == 'A',1,0)\n    test_out['EJ' + '_A'] = np.where(test_out['EJ'] == 'A',1,0)\n    out_features.append('EJ' + '_A')\n    \n    return train_out,test_out,out_features\n\n\n# Only for Train\n_ = preprocess_train(train=dataset_df, numeric_features=WoE_Columns, save_path='/kaggle/working/WoE.pickle')\n\n# For Train & Inference\ntrain_out,test_out,features = preprocess_inference(train=dataset_df, test=dataset_test_df,\n                                               stats=basic_stats_1, numeric_features=WoE_Columns,\n                                              save_path='/kaggle/working/WoE.pickle')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T18:50:15.859344Z","iopub.execute_input":"2023-07-28T18:50:15.859756Z","iopub.status.idle":"2023-07-28T18:50:36.002287Z","shell.execute_reply.started":"2023-07-28T18:50:15.859724Z","shell.execute_reply":"2023-07-28T18:50:36.001232Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"WoE Encoding:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0739e47b66004d8daebfdf3f52d19240"}},"metadata":{}},{"name":"stdout","text":"Saved features:  /kaggle/working/WoE.pickle\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"WoE Encoding:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53381022d4984b30b28fde65a115eda6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Split by NA:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1ccf04eba84c16bac793df65c6292f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Normalise Numeric:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c2a05ace1440a58a065e64f2ffb16d"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Train Model\n\nToday, we will use the defaults to create the Random Forest Model. By default the model is set to train for a classification task.\nWe will train a model for each fold and after training we will store the model and metrics. Here, we have chosen `accuracy` and `binary_crossentropy` as the metrics.","metadata":{}},{"cell_type":"code","source":"class BalancedLogLoss(tf.keras.metrics.Metric):\n    def __init__(self, name='balanced_log_loss', **kwargs):\n        super(BalancedLogLoss, self).__init__(name=name, **kwargs)\n        self.log_loss = self.add_weight(name='log_loss', initializer='zeros')\n\n    def update_state(self, y_true: tf.Tensor, y_pred: tf.Tensor, sample_weight=None):\n        \n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        \n        # Correct Values\n        min_val = 1e-15\n        max_val = 0.999999999999999\n        \n        y_pred = tf.math.minimum(y_pred, [max_val])\n        y_pred = tf.math.maximum(y_pred, [min_val])\n        \n        log_y_pred_1 = tf.reshape(K.log(y_pred),[-1,1])\n        log_y_pred_0 = tf.reshape(K.log(1-y_pred),[-1,1])\n\n        y_1 = tf.reshape(y_true,[1,-1])\n        y_0 = 1-y_1\n\n        logloss_1 = -K.dot(y_1,log_y_pred_1)[0][0]/K.sum(y_1)\n        logloss_0 = -K.dot(y_0,log_y_pred_0)[0][0]/K.sum(y_0)\n\n        av_logloss = (logloss_1+logloss_0)/2\n        \n        self.log_loss.assign_add(av_logloss)\n\n    def result(self):\n        return self.log_loss\n\n    def reset_state(self):\n        # The state of the metric will be reset at the start of each epoch.\n        self.log_loss.assign(0.)\n\ndef plot_train_logs(model) -> None:\n\n    logs = model.make_inspector().training_logs()\n\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n    plt.xlabel(\"Number of trees\")\n    plt.ylabel(\"Accuracy (out-of-bag)\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n    plt.xlabel(\"Number of trees\")\n    plt.ylabel(\"Logloss (out-of-bag)\")\n\n    plt.show()\n\n\nfrom sklearn.base import BaseEstimator \nfrom sklearn.base import RegressorMixin\n    \nclass TFDF_CV_Ensemble(RegressorMixin,BaseEstimator):\n    def __init__(self, model_obj = tfdf.keras.RandomForestModel, label = \"Class\"):\n        self.label: str = label\n        self.model_obj = model_obj\n        \n        # Empty\n        self.X_summary: pd.DataFrame = pd.DataFrame()\n        self.valid_summary: pd.DataFrame = pd.DataFrame()\n        self.features: list = list()\n        self.models: dict = dict()\n        self.metrics: dict = dict()\n        \n        \n    def _compute_weights(self, df: pd.DataFrame) -> dict:\n        # Calculate the number of samples for each label.\n        neg, pos = np.bincount(df[self.label])\n        total = neg + pos\n        weight_for_0 = (1 / neg) * (total / 2.0)\n        weight_for_1 = (1 / pos) * (total / 2.0)\n        class_weight = {0: weight_for_0, 1: weight_for_1}\n        \n        return class_weight\n        \n    def fit(self, X: pd.DataFrame, features: list, splitter = StratifiedKFold(),\n            model_kwargs = dict(), model_compile_kwargs = dict()):\n\n        n_splits = splitter.get_n_splits()\n\n        # Create a various frames\n        self.X_summary = pd.DataFrame(data=np.full((len(X.index),n_splits), np.nan), index=X.index) # For In-Sample Predictions of each Fold\n        self.valid_summary = pd.DataFrame(data=np.full((len(X.index),1), np.nan), index=X.index) # For Out-of-Sample Prediction of each Fold\n        self.features: list = features\n        \n        # Create an empty dictionary to store the models Xed for each fold.\n        self.models = {}\n        self.metrics = {}\n        balanced_logloss_train = {}\n        balanced_logloss_val = {}\n\n        class_weight: dict = self._compute_weights(X)\n        \n        for i, (train_index, valid_index) in enumerate(splitter.split(X=X,y=X['Class'])):\n                print('##### Fold',i+1)\n\n                # Fetch values corresponding to the index \n                train_df = X.iloc[train_index]\n                valid_df = X.iloc[valid_index]\n                valid_ids = valid_df.index.values\n                train_ids = train_df.index.values\n\n                # Select only feature columns for training.\n                train_df = train_df[self.features+[self.label]]\n                valid_df = valid_df[self.features+[self.label]]\n\n                # We need to convert the datatset from Pandas format (pd.DataFrame)\n                train_tf = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=self.label)\n                valid_tf = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df, label=self.label)\n\n                # Define & Train the model and metrics\n                model = self.model_obj(**model_kwargs)\n                model.compile(**model_compile_kwargs) \n                model.fit(x=train_tf, class_weight=class_weight)\n\n                # Store the model\n                self.models[i] = model\n\n                # Predict Values\n                self.X_summary.loc[train_ids, i] = model.predict(x=train_tf).flatten()\n                self.valid_summary.loc[valid_ids, 0] = model.predict(x=valid_tf).flatten()\n\n                # Evaluate and store the metrics in respective dicts\n                evaluation = model.evaluate(x=train_tf,return_dict=True)\n                train_metric = evaluation[\"balanced_log_loss\"]\n\n                evaluation = model.evaluate(x=valid_tf,return_dict=True)\n                val_metric = evaluation[\"balanced_log_loss\"]\n\n                # Plot Results\n                plot_train_logs(model)\n\n                balanced_logloss_train[i] = train_metric\n                balanced_logloss_val[i] = val_metric\n\n                print(f\"\\nTrain: {train_metric:.4f} Validation: {val_metric:.4f}\")\n\n        self.metrics['train'] = balanced_logloss_train\n        self.metrics['val'] = balanced_logloss_val\n\n        print(f\"\\nTrain mean: {pd.Series(self.metrics['train']).mean():.4f} std: {pd.Series(self.metrics['train']).std():.4f}\")\n        print(f\"\\nValidation mean: {pd.Series(self.metrics['val']).mean():.4f} std: {pd.Series(self.metrics['val']).std():.4f}\")\n        \n        return self\n    \n    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n        \n        X_tf = tfdf.keras.pd_dataframe_to_tf_dataset(X) # Technial, to conert frame to tensor for makind a predictions using tensor framework\n        X_summary = pd.DataFrame(data=np.full((len(X.index),n_splits), np.nan),index=X.index) # For X (Sumbition) Predictions of each Fold's Model\n\n        for i, model in enumerate(self.models.values()):\n            X_summary[i] = model.predict(x=X_tf).flatten() \n        \n        return X_summary\n    \n    def save(self, save_path: str) -> None:\n        try:\n            shutil.rmtree(save_path)\n        except FileNotFoundError:\n            pass\n        else:\n            pass\n            \n        os.makedirs(f'{save_path}/models', exist_ok=True)\n        \n        for fold, model in self.models.items():\n            # model.save(filepath=f'{save_path}/models/{fold}')\n            joblib.dump(value=model, filename=f'{save_path}/models/{fold}.pickle')\n        \n        # TODO: Other attributes\n        joblib.dump(value=self.label, filename=f'{save_path}/label.pickle')\n        joblib.dump(value=self.model_obj, filename=f'{save_path}/model_obj.pickle')\n        \n        joblib.dump(value=self.X_summary, filename=f'{save_path}/X_summary.pickle')\n        joblib.dump(value=self.valid_summary, filename=f'{save_path}/valid_summary.pickle')\n        joblib.dump(value=self.features, filename=f'{save_path}/features.pickle')\n        joblib.dump(value=self.metrics, filename=f'{save_path}/metrics.pickle')\n            \n        return None\n    \n    def load(self, save_path: str):\n        \n        # TODO: Other attributes\n        self.label = joblib.load(filename=f'{save_path}/label.pickle')\n        self.model_obj = joblib.load(filename=f'{save_path}/model_obj.pickle')\n        \n        self.X_summary = joblib.load(filename=f'{save_path}/X_summary.pickle')\n        self.valid_summary = joblib.load(filename=f'{save_path}/valid_summary.pickle')\n        self.features = joblib.load(filename=f'{save_path}/features.pickle')\n        self.metrics = joblib.load(filename=f'{save_path}/metrics.pickle')\n        \n        self.models = dict()\n        \n        for name in os.listdir(f'{save_path}/models'):\n            i = name.split('.')[0]\n            self.models[int(i)] = joblib.load(filename=f'{save_path}/models/{name}')\n            \n        return self\n    \n\n# Test\nmy_splitter = StratifiedKFold(n_splits=2,shuffle=True, random_state=1902)\n\n# initialise\nCV_Ensemble_1 = TFDF_CV_Ensemble(model_obj=tfdf.keras.RandomForestModel, label=\"Class\")\n\n# train\nCV_Ensemble_1 = CV_Ensemble_1.fit(X=train_out, features=features, \n                                  splitter=my_splitter,\n                                  model_kwargs=dict(max_depth=6, num_trees=1000),\n                                  model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]))\n\n# save\nCV_Ensemble_1.save(save_path='/kaggle/working/RF/1')\n\n# # RandomForestModel\n# if not SUBMITION:\n#     train_summary_rf_1, valid_summary_rf_1, test_summary_rf_1, model_rf_1,metrics_rf_1 = train_model(\n#         train=train_out,test=test_out, features=features,\n#         splitter=my_splitter,\n#         model_obj=tfdf.keras.RandomForestModel,\n#         model_kwargs=dict(max_depth=6, num_trees=1000),\n#         model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]),\n#         save_path = '/kaggle/working/RF/1'\n#     )","metadata":{"execution":{"iopub.status.busy":"2023-07-28T20:58:47.531793Z","iopub.execute_input":"2023-07-28T20:58:47.532278Z","iopub.status.idle":"2023-07-28T20:59:00.017833Z","shell.execute_reply.started":"2023-07-28T20:58:47.532247Z","shell.execute_reply":"2023-07-28T20:59:00.016628Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"##### Fold 1\nUse /tmp/tmpysgv_zf5 as temporary training directory\nReading training dataset...\nTraining dataset read in 0:00:01.943482. Found 308 examples.\nTraining model...\nModel trained in 0:00:00.458622\nCompiling model...\n","output_type":"stream"},{"name":"stderr","text":"[INFO 23-07-28 20:58:50.9168 UTC kernel.cc:1242] Loading model from path /tmp/tmpysgv_zf5/model/ with prefix 744e8f18cad24fa8\n[INFO 23-07-28 20:58:51.0067 UTC decision_forest.cc:660] Model loaded with 1000 root(s), 25702 node(s), and 113 input feature(s).\n[INFO 23-07-28 20:58:51.0068 UTC abstract_model.cc:1311] Engine \"RandomForestOptPred\" built\n[INFO 23-07-28 20:58:51.0068 UTC kernel.cc:1074] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Model compiled.\n1/1 [==============================] - 0s 278ms/step\n1/1 [==============================] - 0s 262ms/step\n1/1 [==============================] - 1s 561ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9935 - balanced_log_loss: 0.1899\n1/1 [==============================] - 0s 379ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9320 - balanced_log_loss: 0.3693\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nTrain: 0.1899 Validation: 0.3693\n##### Fold 2\nUse /tmp/tmp0kf8zs6p as temporary training directory\nReading training dataset...\nTraining dataset read in 0:00:01.822191. Found 309 examples.\nTraining model...\nModel trained in 0:00:00.446655\nCompiling model...\n","output_type":"stream"},{"name":"stderr","text":"[INFO 23-07-28 20:58:57.0739 UTC kernel.cc:1242] Loading model from path /tmp/tmp0kf8zs6p/model/ with prefix 6e6ddaa116fd46c9\n[INFO 23-07-28 20:58:57.1608 UTC decision_forest.cc:660] Model loaded with 1000 root(s), 25796 node(s), and 113 input feature(s).\n[INFO 23-07-28 20:58:57.1609 UTC kernel.cc:1074] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Model compiled.\n1/1 [==============================] - 0s 260ms/step\n1/1 [==============================] - 0s 259ms/step\n1/1 [==============================] - 1s 558ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9806 - balanced_log_loss: 0.5218\n1/1 [==============================] - 0s 382ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9188 - balanced_log_loss: 0.4127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nTrain: 0.5218 Validation: 0.4127\n\nTrain mean: 0.3559 std: 0.2347\n\nValidation mean: 0.3910 std: 0.0307\n","output_type":"stream"}]},{"cell_type":"code","source":"# load\nCV_Ensemble_1_load = TFDF_CV_Ensemble()\n\nCV_Ensemble_1_load = CV_Ensemble_1_load.load(save_path='/kaggle/working/RF/1')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T20:59:00.019459Z","iopub.execute_input":"2023-07-28T20:59:00.019777Z","iopub.status.idle":"2023-07-28T20:59:00.061379Z","shell.execute_reply.started":"2023-07-28T20:59:00.019751Z","shell.execute_reply":"2023-07-28T20:59:00.060275Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Use /tmp/tmplvaeo3k_ as temporary training directory\nUse /tmp/tmp5mllem1f as temporary training directory\n","output_type":"stream"}]},{"cell_type":"code","source":"CV_Ensemble_1_load.models","metadata":{"execution":{"iopub.status.busy":"2023-07-28T20:59:09.815835Z","iopub.execute_input":"2023-07-28T20:59:09.816257Z","iopub.status.idle":"2023-07-28T20:59:09.824593Z","shell.execute_reply.started":"2023-07-28T20:59:09.816219Z","shell.execute_reply":"2023-07-28T20:59:09.823403Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"{0: <tensorflow_decision_forests.keras.RandomForestModel at 0x7f12c2a5a290>,\n 1: <tensorflow_decision_forests.keras.RandomForestModel at 0x7f13dd5a53c0>}"},"metadata":{}}]},{"cell_type":"code","source":"# Let's try to find Cutoffs organically\ntrain_summary_rf_1_mean = train_summary_rf_1.mean(axis=1)\ntrain_summary_rf_1_mean.name = 'Pred'\n\ntmp = pd.concat([train_summary_rf_1_mean, train_out['Class']], axis=1).sort_index(ascending=True)\n\ntmp['Pred_Bins'] = pd.qcut(x=tmp['Pred'],q=100)\ntmp = tmp.groupby('Pred_Bins')['Class'].agg({'sum','count'})\ntmp['count_cumsum'] = tmp['count'].cumsum()\ntmp['sum_cumsum'] = tmp['sum'].cumsum()\n\ntmp['bads_rate'] = tmp['sum_cumsum']/tmp['count_cumsum']\n\ntmp['perc_sum'] = [*range(1,101)]\n\ntmp\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T12:39:53.780614Z","iopub.execute_input":"2023-07-28T12:39:53.781066Z","iopub.status.idle":"2023-07-28T12:39:53.833208Z","shell.execute_reply.started":"2023-07-28T12:39:53.781031Z","shell.execute_reply":"2023-07-28T12:39:53.832045Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                  count  sum  count_cumsum  sum_cumsum  \\\nPred_Bins                                                                \n(0.0006000000000000001, 0.00706]      7    0             7           0   \n(0.00706, 0.00979]                    6    0            13           0   \n(0.00979, 0.0128]                     6    0            19           0   \n(0.0128, 0.0153]                      6    0            25           0   \n(0.0153, 0.0175]                      6    0            31           0   \n(0.0175, 0.0186]                      6    0            37           0   \n(0.0186, 0.0206]                      7    0            44           0   \n(0.0206, 0.0236]                      6    0            50           0   \n(0.0236, 0.0259]                      6    0            56           0   \n(0.0259, 0.0282]                      6    0            62           0   \n(0.0282, 0.0301]                      6    0            68           0   \n(0.0301, 0.0312]                      6    0            74           0   \n(0.0312, 0.0322]                      7    0            81           0   \n(0.0322, 0.0337]                      6    0            87           0   \n(0.0337, 0.0348]                      6    0            93           0   \n(0.0348, 0.0369]                      6    0            99           0   \n(0.0369, 0.0382]                      6    0           105           0   \n(0.0382, 0.0396]                      6    0           111           0   \n(0.0396, 0.0408]                      7    0           118           0   \n(0.0408, 0.0424]                      6    0           124           0   \n(0.0424, 0.0453]                      6    0           130           0   \n(0.0453, 0.0467]                      6    0           136           0   \n(0.0467, 0.0483]                      6    0           142           0   \n(0.0483, 0.0498]                      6    0           148           0   \n(0.0498, 0.052]                       7    0           155           0   \n(0.052, 0.054]                        6    0           161           0   \n(0.054, 0.0567]                       6    0           167           0   \n(0.0567, 0.0579]                      6    0           173           0   \n(0.0579, 0.0597]                      6    0           179           0   \n(0.0597, 0.0616]                      6    0           185           0   \n(0.0616, 0.063]                       6    0           191           0   \n(0.063, 0.065]                        7    0           198           0   \n(0.065, 0.0671]                       6    0           204           0   \n(0.0671, 0.0694]                      6    0           210           0   \n(0.0694, 0.0716]                      6    0           216           0   \n(0.0716, 0.0728]                      6    0           222           0   \n(0.0728, 0.0738]                      6    0           228           0   \n(0.0738, 0.0766]                      7    0           235           0   \n(0.0766, 0.0799]                      6    0           241           0   \n(0.0799, 0.0827]                      6    0           247           0   \n(0.0827, 0.0849]                      6    0           253           0   \n(0.0849, 0.0874]                      7    0           260           0   \n(0.0874, 0.0901]                      5    0           265           0   \n(0.0901, 0.0924]                      7    0           272           0   \n(0.0924, 0.0946]                      6    0           278           0   \n(0.0946, 0.0978]                      6    0           284           0   \n(0.0978, 0.101]                       7    0           291           0   \n(0.101, 0.103]                        5    0           296           0   \n(0.103, 0.105]                        6    0           302           0   \n(0.105, 0.106]                        7    0           309           0   \n(0.106, 0.111]                        6    0           315           0   \n(0.111, 0.114]                        7    0           322           0   \n(0.114, 0.115]                        5    0           327           0   \n(0.115, 0.119]                        6    0           333           0   \n(0.119, 0.122]                        6    0           339           0   \n(0.122, 0.123]                        7    0           346           0   \n(0.123, 0.127]                        6    0           352           0   \n(0.127, 0.133]                        6    0           358           0   \n(0.133, 0.138]                        6    0           364           0   \n(0.138, 0.143]                        6    0           370           0   \n(0.143, 0.147]                        6    0           376           0   \n(0.147, 0.154]                        6    0           382           0   \n(0.154, 0.158]                        7    0           389           0   \n(0.158, 0.165]                        7    0           396           0   \n(0.165, 0.169]                        5    0           401           0   \n(0.169, 0.174]                        6    0           407           0   \n(0.174, 0.178]                        6    0           413           0   \n(0.178, 0.185]                        6    0           419           0   \n(0.185, 0.191]                        7    0           426           0   \n(0.191, 0.2]                          7    0           433           0   \n(0.2, 0.212]                          5    0           438           0   \n(0.212, 0.224]                        7    0           445           0   \n(0.224, 0.23]                         5    0           450           0   \n(0.23, 0.248]                         6    0           456           0   \n(0.248, 0.274]                        7    0           463           0   \n(0.274, 0.287]                        6    0           469           0   \n(0.287, 0.32]                         6    0           475           0   \n(0.32, 0.352]                         6    0           481           0   \n(0.352, 0.406]                        6    1           487           1   \n(0.406, 0.431]                        6    2           493           3   \n(0.431, 0.515]                        6    1           499           4   \n(0.515, 0.552]                        7    3           506           7   \n(0.552, 0.576]                        6    1           512           8   \n(0.576, 0.658]                        6    2           518          10   \n(0.658, 0.708]                        6    5           524          15   \n(0.708, 0.768]                        6    6           530          21   \n(0.768, 0.79]                         6    6           536          27   \n(0.79, 0.813]                         7    7           543          34   \n(0.813, 0.836]                        6    6           549          40   \n(0.836, 0.848]                        6    6           555          46   \n(0.848, 0.861]                        6    6           561          52   \n(0.861, 0.874]                        6    6           567          58   \n(0.874, 0.88]                         7    7           574          65   \n(0.88, 0.887]                         6    6           580          71   \n(0.887, 0.892]                        6    6           586          77   \n(0.892, 0.9]                          6    6           592          83   \n(0.9, 0.911]                          6    6           598          89   \n(0.911, 0.921]                        6    6           604          95   \n(0.921, 0.938]                        6    6           610         101   \n(0.938, 0.966]                        7    7           617         108   \n\n                                  bads_rate  perc_sum  \nPred_Bins                                              \n(0.0006000000000000001, 0.00706]   0.000000         1  \n(0.00706, 0.00979]                 0.000000         2  \n(0.00979, 0.0128]                  0.000000         3  \n(0.0128, 0.0153]                   0.000000         4  \n(0.0153, 0.0175]                   0.000000         5  \n(0.0175, 0.0186]                   0.000000         6  \n(0.0186, 0.0206]                   0.000000         7  \n(0.0206, 0.0236]                   0.000000         8  \n(0.0236, 0.0259]                   0.000000         9  \n(0.0259, 0.0282]                   0.000000        10  \n(0.0282, 0.0301]                   0.000000        11  \n(0.0301, 0.0312]                   0.000000        12  \n(0.0312, 0.0322]                   0.000000        13  \n(0.0322, 0.0337]                   0.000000        14  \n(0.0337, 0.0348]                   0.000000        15  \n(0.0348, 0.0369]                   0.000000        16  \n(0.0369, 0.0382]                   0.000000        17  \n(0.0382, 0.0396]                   0.000000        18  \n(0.0396, 0.0408]                   0.000000        19  \n(0.0408, 0.0424]                   0.000000        20  \n(0.0424, 0.0453]                   0.000000        21  \n(0.0453, 0.0467]                   0.000000        22  \n(0.0467, 0.0483]                   0.000000        23  \n(0.0483, 0.0498]                   0.000000        24  \n(0.0498, 0.052]                    0.000000        25  \n(0.052, 0.054]                     0.000000        26  \n(0.054, 0.0567]                    0.000000        27  \n(0.0567, 0.0579]                   0.000000        28  \n(0.0579, 0.0597]                   0.000000        29  \n(0.0597, 0.0616]                   0.000000        30  \n(0.0616, 0.063]                    0.000000        31  \n(0.063, 0.065]                     0.000000        32  \n(0.065, 0.0671]                    0.000000        33  \n(0.0671, 0.0694]                   0.000000        34  \n(0.0694, 0.0716]                   0.000000        35  \n(0.0716, 0.0728]                   0.000000        36  \n(0.0728, 0.0738]                   0.000000        37  \n(0.0738, 0.0766]                   0.000000        38  \n(0.0766, 0.0799]                   0.000000        39  \n(0.0799, 0.0827]                   0.000000        40  \n(0.0827, 0.0849]                   0.000000        41  \n(0.0849, 0.0874]                   0.000000        42  \n(0.0874, 0.0901]                   0.000000        43  \n(0.0901, 0.0924]                   0.000000        44  \n(0.0924, 0.0946]                   0.000000        45  \n(0.0946, 0.0978]                   0.000000        46  \n(0.0978, 0.101]                    0.000000        47  \n(0.101, 0.103]                     0.000000        48  \n(0.103, 0.105]                     0.000000        49  \n(0.105, 0.106]                     0.000000        50  \n(0.106, 0.111]                     0.000000        51  \n(0.111, 0.114]                     0.000000        52  \n(0.114, 0.115]                     0.000000        53  \n(0.115, 0.119]                     0.000000        54  \n(0.119, 0.122]                     0.000000        55  \n(0.122, 0.123]                     0.000000        56  \n(0.123, 0.127]                     0.000000        57  \n(0.127, 0.133]                     0.000000        58  \n(0.133, 0.138]                     0.000000        59  \n(0.138, 0.143]                     0.000000        60  \n(0.143, 0.147]                     0.000000        61  \n(0.147, 0.154]                     0.000000        62  \n(0.154, 0.158]                     0.000000        63  \n(0.158, 0.165]                     0.000000        64  \n(0.165, 0.169]                     0.000000        65  \n(0.169, 0.174]                     0.000000        66  \n(0.174, 0.178]                     0.000000        67  \n(0.178, 0.185]                     0.000000        68  \n(0.185, 0.191]                     0.000000        69  \n(0.191, 0.2]                       0.000000        70  \n(0.2, 0.212]                       0.000000        71  \n(0.212, 0.224]                     0.000000        72  \n(0.224, 0.23]                      0.000000        73  \n(0.23, 0.248]                      0.000000        74  \n(0.248, 0.274]                     0.000000        75  \n(0.274, 0.287]                     0.000000        76  \n(0.287, 0.32]                      0.000000        77  \n(0.32, 0.352]                      0.000000        78  \n(0.352, 0.406]                     0.002053        79  \n(0.406, 0.431]                     0.006085        80  \n(0.431, 0.515]                     0.008016        81  \n(0.515, 0.552]                     0.013834        82  \n(0.552, 0.576]                     0.015625        83  \n(0.576, 0.658]                     0.019305        84  \n(0.658, 0.708]                     0.028626        85  \n(0.708, 0.768]                     0.039623        86  \n(0.768, 0.79]                      0.050373        87  \n(0.79, 0.813]                      0.062615        88  \n(0.813, 0.836]                     0.072860        89  \n(0.836, 0.848]                     0.082883        90  \n(0.848, 0.861]                     0.092692        91  \n(0.861, 0.874]                     0.102293        92  \n(0.874, 0.88]                      0.113240        93  \n(0.88, 0.887]                      0.122414        94  \n(0.887, 0.892]                     0.131399        95  \n(0.892, 0.9]                       0.140203        96  \n(0.9, 0.911]                       0.148829        97  \n(0.911, 0.921]                     0.157285        98  \n(0.921, 0.938]                     0.165574        99  \n(0.938, 0.966]                     0.175041       100  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>sum</th>\n      <th>count_cumsum</th>\n      <th>sum_cumsum</th>\n      <th>bads_rate</th>\n      <th>perc_sum</th>\n    </tr>\n    <tr>\n      <th>Pred_Bins</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(0.0006000000000000001, 0.00706]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(0.00706, 0.00979]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>(0.00979, 0.0128]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>(0.0128, 0.0153]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>(0.0153, 0.0175]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>31</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>(0.0175, 0.0186]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>(0.0186, 0.0206]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>(0.0206, 0.0236]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>(0.0236, 0.0259]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>(0.0259, 0.0282]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>62</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>(0.0282, 0.0301]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>(0.0301, 0.0312]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>(0.0312, 0.0322]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>(0.0322, 0.0337]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>87</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>(0.0337, 0.0348]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>93</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>(0.0348, 0.0369]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>99</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>(0.0369, 0.0382]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>105</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>(0.0382, 0.0396]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>111</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>(0.0396, 0.0408]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>(0.0408, 0.0424]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>124</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>(0.0424, 0.0453]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>130</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>(0.0453, 0.0467]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>136</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>(0.0467, 0.0483]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>142</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>(0.0483, 0.0498]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>148</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>(0.0498, 0.052]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>155</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>(0.052, 0.054]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>161</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>(0.054, 0.0567]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>167</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>(0.0567, 0.0579]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>173</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>(0.0579, 0.0597]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>179</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>(0.0597, 0.0616]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>185</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>(0.0616, 0.063]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>191</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>(0.063, 0.065]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>198</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>(0.065, 0.0671]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>(0.0671, 0.0694]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>210</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>(0.0694, 0.0716]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>(0.0716, 0.0728]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>222</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>(0.0728, 0.0738]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>228</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>(0.0738, 0.0766]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>235</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>(0.0766, 0.0799]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>241</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>(0.0799, 0.0827]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>247</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>(0.0827, 0.0849]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>253</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>(0.0849, 0.0874]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>260</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>(0.0874, 0.0901]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>265</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>(0.0901, 0.0924]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>(0.0924, 0.0946]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>278</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>(0.0946, 0.0978]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>284</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>(0.0978, 0.101]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>291</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>(0.101, 0.103]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>296</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>(0.103, 0.105]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>302</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>(0.105, 0.106]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>309</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>(0.106, 0.111]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>315</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>(0.111, 0.114]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>322</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>(0.114, 0.115]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>327</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>(0.115, 0.119]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>333</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>(0.119, 0.122]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>339</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>(0.122, 0.123]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>346</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>(0.123, 0.127]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>352</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>(0.127, 0.133]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>(0.133, 0.138]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>364</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>(0.138, 0.143]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>370</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>(0.143, 0.147]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>376</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>(0.147, 0.154]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>382</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>(0.154, 0.158]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>389</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>(0.158, 0.165]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>396</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>(0.165, 0.169]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>401</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>(0.169, 0.174]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>407</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>(0.174, 0.178]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>413</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>(0.178, 0.185]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>419</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>(0.185, 0.191]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>426</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>(0.191, 0.2]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>433</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>(0.2, 0.212]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>438</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>(0.212, 0.224]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>445</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>(0.224, 0.23]</th>\n      <td>5</td>\n      <td>0</td>\n      <td>450</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>(0.23, 0.248]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>456</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>(0.248, 0.274]</th>\n      <td>7</td>\n      <td>0</td>\n      <td>463</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>(0.274, 0.287]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>469</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>(0.287, 0.32]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>475</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>(0.32, 0.352]</th>\n      <td>6</td>\n      <td>0</td>\n      <td>481</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>(0.352, 0.406]</th>\n      <td>6</td>\n      <td>1</td>\n      <td>487</td>\n      <td>1</td>\n      <td>0.002053</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>(0.406, 0.431]</th>\n      <td>6</td>\n      <td>2</td>\n      <td>493</td>\n      <td>3</td>\n      <td>0.006085</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>(0.431, 0.515]</th>\n      <td>6</td>\n      <td>1</td>\n      <td>499</td>\n      <td>4</td>\n      <td>0.008016</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>(0.515, 0.552]</th>\n      <td>7</td>\n      <td>3</td>\n      <td>506</td>\n      <td>7</td>\n      <td>0.013834</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>(0.552, 0.576]</th>\n      <td>6</td>\n      <td>1</td>\n      <td>512</td>\n      <td>8</td>\n      <td>0.015625</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>(0.576, 0.658]</th>\n      <td>6</td>\n      <td>2</td>\n      <td>518</td>\n      <td>10</td>\n      <td>0.019305</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>(0.658, 0.708]</th>\n      <td>6</td>\n      <td>5</td>\n      <td>524</td>\n      <td>15</td>\n      <td>0.028626</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>(0.708, 0.768]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>530</td>\n      <td>21</td>\n      <td>0.039623</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>(0.768, 0.79]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>536</td>\n      <td>27</td>\n      <td>0.050373</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>(0.79, 0.813]</th>\n      <td>7</td>\n      <td>7</td>\n      <td>543</td>\n      <td>34</td>\n      <td>0.062615</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>(0.813, 0.836]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>549</td>\n      <td>40</td>\n      <td>0.072860</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>(0.836, 0.848]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>555</td>\n      <td>46</td>\n      <td>0.082883</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>(0.848, 0.861]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>561</td>\n      <td>52</td>\n      <td>0.092692</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>(0.861, 0.874]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>567</td>\n      <td>58</td>\n      <td>0.102293</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>(0.874, 0.88]</th>\n      <td>7</td>\n      <td>7</td>\n      <td>574</td>\n      <td>65</td>\n      <td>0.113240</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>(0.88, 0.887]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>580</td>\n      <td>71</td>\n      <td>0.122414</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>(0.887, 0.892]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>586</td>\n      <td>77</td>\n      <td>0.131399</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>(0.892, 0.9]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>592</td>\n      <td>83</td>\n      <td>0.140203</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>(0.9, 0.911]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>598</td>\n      <td>89</td>\n      <td>0.148829</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>(0.911, 0.921]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>604</td>\n      <td>95</td>\n      <td>0.157285</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>(0.921, 0.938]</th>\n      <td>6</td>\n      <td>6</td>\n      <td>610</td>\n      <td>101</td>\n      <td>0.165574</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>(0.938, 0.966]</th>\n      <td>7</td>\n      <td>7</td>\n      <td>617</td>\n      <td>108</td>\n      <td>0.175041</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# RandomForestModel","metadata":{}},{"cell_type":"code","source":"# RandomForestModel\nif not SUBMITION:\n    train_summary_rf_1, valid_summary_rf_1, test_summary_rf_1, model_rf_1,metrics_rf_1 = train_model(\n        train=train_out,test=test_out, features=features,\n        n_splits=6,\n        model_obj=tfdf.keras.RandomForestModel,\n        model_kwargs=dict(max_depth=6, num_trees=1000),\n        model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:28:58.714677Z","iopub.execute_input":"2023-07-22T06:28:58.715036Z","iopub.status.idle":"2023-07-22T06:29:54.982233Z","shell.execute_reply.started":"2023-07-22T06:28:58.714999Z","shell.execute_reply":"2023-07-22T06:29:54.980987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestModel\nif not SUBMITION:\n    train_summary_rf_2, valid_summary_rf_2, test_summary_rf_2, model_rf_2,metrics_rf_2 = train_model(\n        train=train_out,test=test_out, features=features,                                             \n        n_splits=10,                    \n        model_obj=tfdf.keras.RandomForestModel,           \n        model_kwargs=dict(max_depth=6, num_trees=300),                                                  \n        model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:29:54.983882Z","iopub.execute_input":"2023-07-22T06:29:54.984307Z","iopub.status.idle":"2023-07-22T06:31:10.290925Z","shell.execute_reply.started":"2023-07-22T06:29:54.984274Z","shell.execute_reply":"2023-07-22T06:31:10.289651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestModel\n\nfeatures_slice = [i for i in features if len(i) > 2]\n\ntrain_summary_rf_3, valid_summary_rf_3, test_summary_rf_3, model_rf_3,metrics_rf_3 = train_model(\n    train=train_out,test=test_out, features=features_slice,                                             \n    n_splits=10,                    \n    model_obj=tfdf.keras.RandomForestModel,           \n    model_kwargs=dict(max_depth=6, num_trees=300),                                                  \n    model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:31:10.292950Z","iopub.execute_input":"2023-07-22T06:31:10.293438Z","iopub.status.idle":"2023-07-22T06:31:56.937132Z","shell.execute_reply.started":"2023-07-22T06:31:10.293396Z","shell.execute_reply":"2023-07-22T06:31:56.936084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestModel\n\nfeatures_slice = [i for i in features if len(i) > 2]\n\ntrain_summary_rf_3, valid_summary_rf_3, test_summary_rf_3, model_rf_3,metrics_rf_3 = train_model(\n    train=train_out,test=test_out, features=features_slice,                                             \n    n_splits=10,                    \n    model_obj=tfdf.keras.RandomForestModel,           \n    model_kwargs=dict(max_depth=6, num_trees=300),                                                  \n    model_compile_kwargs=dict(metrics=[metrics.binary_accuracy,BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:31:56.938508Z","iopub.execute_input":"2023-07-22T06:31:56.940343Z","iopub.status.idle":"2023-07-22T06:32:43.537911Z","shell.execute_reply.started":"2023-07-22T06:31:56.940307Z","shell.execute_reply":"2023-07-22T06:32:43.536602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradientBoostedTreesModel","metadata":{}},{"cell_type":"code","source":"# GradientBoostedTreesModel\n\nif not SUBMITION:\n\n    features_slice = [i for i in features if len(i) > 2]\n\n    train_summary_gbt_1, valid_summary_gbt_1, test_summary_gbt_1, model_gbt_1,metrics_gbt_1 = train_model(\n        train=train_out,test=test_out, features=features_slice,                                             \n        n_splits=10,                    \n        model_obj=tfdf.keras.GradientBoostedTreesModel,            \n        model_kwargs=dict(max_depth=5, num_trees=1000),                                                  \n        model_compile_kwargs=dict(metrics=[metrics.binary_accuracy, BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:32:43.540450Z","iopub.execute_input":"2023-07-22T06:32:43.541019Z","iopub.status.idle":"2023-07-22T06:33:49.767994Z","shell.execute_reply.started":"2023-07-22T06:32:43.540985Z","shell.execute_reply":"2023-07-22T06:33:49.765943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GradientBoostedTreesModel\n\nfeatures_slice = [i for i in features if len(i) > 2]\n\ntrain_summary_gbt_2, valid_summary_gbt_2, test_summary_gbt_2, model_gbt_2,metrics_gbt_2 = train_model(\n    train=train_out,test=test_out, features=features_slice,                                             \n    n_splits=10,                    \n    model_obj=tfdf.keras.GradientBoostedTreesModel,            \n    model_kwargs=dict(max_depth=2, num_trees=1000),                                                  \n    model_compile_kwargs=dict(metrics=[metrics.binary_accuracy, BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:33:49.769795Z","iopub.execute_input":"2023-07-22T06:33:49.771485Z","iopub.status.idle":"2023-07-22T06:34:46.177812Z","shell.execute_reply.started":"2023-07-22T06:33:49.771433Z","shell.execute_reply":"2023-07-22T06:34:46.176573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TabPFN","metadata":{}},{"cell_type":"code","source":"def balanced_logloss_np(y_true: np.array, y_pred: np.array) -> float:\n    \n    # Correct Values\n    min_val = 1e-15\n    max_val = 0.999999999999999\n\n    y_pred = np.minimum(y_pred, [max_val])\n    y_pred = np.maximum(y_pred, [min_val])\n    \n    y_pred_1 = y_pred\n    y_pred_0 = 1-y_pred\n\n    log_y_pred_1 = np.reshape(np.log(y_pred_1),[-1,1])\n    log_y_pred_0 = np.reshape(np.log(y_pred_0),[-1,1])\n\n    y_1 = np.reshape(y_true,[1,-1])\n    y_0 = (y_1-1)*(-1)\n\n    logloss_1 = -np.dot(y_1,log_y_pred_1)[0][0]/np.sum(y_1)\n    logloss_0 = -np.dot(y_0,log_y_pred_0)[0][0]/np.sum(y_0)\n\n    av_logloss = (logloss_1+logloss_0)/2\n    \n    return av_logloss\n\ndef train_model_tabpfn_one(train: pd.DataFrame, test: pd.DataFrame, features: list, label = \"Class\") -> (pd.DataFrame, dict, dict):\n\n    # Create a dataframe of required size with zero values.\n    test_summary = pd.DataFrame(data=np.full((len(test.index),1), np.nan),index=test.index)\n    train_summary = pd.DataFrame(data=np.full((len(train.index),1), np.nan),index=train.index)\n    # Create an empty dictionary to store the models trained for each fold.\n    metrics = {}\n\n    # Select only feature columns for training.\n    train_df = train[features+[label]]\n\n    # Define & Train the model and metrics\n    model = TabPFNClassifier(N_ensemble_configurations=64)\n    model.fit(train_df[features],train_df[label])\n\n    # Make predictions\n    p_train = model.predict_proba(train_df[features])[:,1]\n    p_test = model.predict_proba(test[features])[:,1]\n\n    # Predict value for validation/Submition data\n    test_summary[0] = p_test.flatten() \n    train_summary[0] = p_train.flatten() \n    \n    # Evaluate and store the metrics in respective dicts\n    metrics['balanced_logloss'] = balanced_logloss_np(y_true=train_df[label].values,y_pred=p_train)\n    print(f\"\\nTrain: {metrics['balanced_logloss']:.4f}\")\n    \n            \n    return train_summary, test_summary, model, metrics\n\n\ndef train_model_tabpfn_cv(train: pd.DataFrame, test: pd.DataFrame, features: list, label = \"Class\",\n                n_splits: int = 6) -> (pd.DataFrame, dict,  dict):\n\n    # Create a various frames\n    train_summary = pd.DataFrame(data=np.full((len(train.index),n_splits), np.nan), index=train.index) # For In-Sample Predictions of each Fold\n    \n    valid_summary = pd.DataFrame(data=np.full((len(train.index),1), np.nan), index=train.index) # For Out-of-Sample Prediction of each Fold\n    \n    test_summary = pd.DataFrame(data=np.full((len(test.index),n_splits), np.nan),index=test.index) # For Test (Sumbition) Predictions of each Fold's Model\n    \n\n    # Create an empty dictionary to store the models trained for each fold.\n    models = {}\n    metrics = {}\n    balanced_logloss_train = {}\n    balanced_logloss_val = {}\n    \n    # Loop through each fold\n    skf = StratifiedKFold(n_splits=n_splits)\n    \n    for i, (train_index, valid_index) in enumerate(skf.split(X=train,y=train['Class'])):\n            print('##### Fold',i+1)\n\n            # Fetch values corresponding to the index \n            train_df = train.iloc[train_index]\n            valid_df = train.iloc[valid_index]\n            train_ids = train_df.index.values\n            valid_ids = valid_df.index.values\n\n            # Select only feature columns for training.\n            train_df = train_df[features+[label]]\n            valid_df = valid_df[features+[label]]\n\n            # Define & Train the model\n            model = TabPFNClassifier(N_ensemble_configurations=64)\n            model.fit(train_df[features],train_df[label])\n\n            # Store the model\n            models[f\"fold_{i+1}\"] = model\n\n            # Predict value for validation/Submition data\n            p_train = model.predict_proba(train_df[features])[:,1]\n            p_val = model.predict_proba(valid_df[features])[:,1]\n            p_sub = model.predict_proba(test[features])[:,1]\n            \n            # Predict Values\n            train_summary.loc[train_ids, i] = p_train\n            valid_summary.loc[valid_ids, 0] = p_val\n            test_summary[i] = p_sub\n\n            # Evaluate and store the metrics in respective dicts\n            train_metric = balanced_logloss_np(y_true=train_df[label].values,y_pred=p_train)\n            val_metric = balanced_logloss_np(y_true=valid_df[label].values,y_pred=p_val)\n            \n            balanced_logloss_train[f\"fold_{i+1}\"] = train_metric\n            balanced_logloss_val[f\"fold_{i+1}\"] = val_metric\n            \n            print(f\"\\nTrain: {train_metric:.4f} Validation: {val_metric:.4f}\")\n    \n    metrics['train'] = balanced_logloss_train\n    metrics['val'] = balanced_logloss_val\n\n    print(f\"\\nTrain mean: {pd.Series(balanced_logloss_train).mean():.4f} std: {pd.Series(balanced_logloss_train).std():.4f}\")\n    print(f\"\\nValidation mean: {pd.Series(balanced_logloss_val).mean():.4f} std: {pd.Series(balanced_logloss_val).std():.4f}\")\n            \n    return train_summary, valid_summary, test_summary, models,metrics","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:34:46.179640Z","iopub.execute_input":"2023-07-22T06:34:46.180125Z","iopub.status.idle":"2023-07-22T06:34:46.209710Z","shell.execute_reply.started":"2023-07-22T06:34:46.180093Z","shell.execute_reply":"2023-07-22T06:34:46.208418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TabPFN tabpfn_\nif not SUBMITION:\n    features_slice = [i for i in features if len(i) > 2]\n    train_summary_tabpfn_1, test_summary_tabpfn_1, model_tabpfn_1, metrics_tabpfn_1 = train_model_tabpfn_one(\n        train=train_out,test=test_out, features=features_slice)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:36:27.489677Z","iopub.execute_input":"2023-07-22T07:36:27.490161Z","iopub.status.idle":"2023-07-22T07:38:28.930962Z","shell.execute_reply.started":"2023-07-22T07:36:27.490111Z","shell.execute_reply":"2023-07-22T07:38:28.929257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TabPFN tabpfn_\nfeatures_slice = [i for i in features if len(i) > 2]\ntrain_summary_tabpfn_2, valid_summary_tabpfn_2, test_summary_tabpfn_2, model_tabpfn_2, metrics_tabpfn_2 = train_model_tabpfn_cv(\n    train=train_out,test=test_out, features=features_slice, n_splits=6)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:36:40.207653Z","iopub.execute_input":"2023-07-22T06:36:40.208129Z","iopub.status.idle":"2023-07-22T06:49:24.120496Z","shell.execute_reply.started":"2023-07-22T06:36:40.208021Z","shell.execute_reply":"2023-07-22T06:49:24.119160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble CV","metadata":{}},{"cell_type":"code","source":"class EnsembleCV(object):\n    def __init__(self):\n        self.is_fitted = False\n        self.weights = None\n        return\n    \n    def fit(self, X: pd.DataFrame) -> None:\n        self.weights = None\n        return\n    \n    @staticmethod\n    def predict(X: pd.DataFrame) -> pd.Series:\n        # Take conservative estimate\n        X_ = X.mean(axis=1) #.to_frame()\n        # Fillna by 1\n        X_ = X_.fillna(1)\n        return X_","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:34:05.234849Z","iopub.execute_input":"2023-07-22T07:34:05.235468Z","iopub.status.idle":"2023-07-22T07:34:05.245644Z","shell.execute_reply.started":"2023-07-22T07:34:05.235422Z","shell.execute_reply":"2023-07-22T07:34:05.244405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_ensemble = EnsembleCV()\ngbt_ensemble = EnsembleCV()\ntabpfn_ensemble = EnsembleCV()\n\ntest_rf_ensemble = rf_ensemble.predict(X=test_summary_rf_3)\ntest_gbt_ensemble = gbt_ensemble.predict(X=test_summary_gbt_2)\ntest_tabpfn_ensemble = tabpfn_ensemble.predict(X=test_summary_tabpfn_1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:52:38.564875Z","iopub.execute_input":"2023-07-22T07:52:38.565353Z","iopub.status.idle":"2023-07-22T07:52:38.574034Z","shell.execute_reply.started":"2023-07-22T07:52:38.565320Z","shell.execute_reply":"2023-07-22T07:52:38.573051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out['Class_RF'] = rf_ensemble.predict(X=train_summary_rf_3)\ntest_out['Class_RF'] = rf_ensemble.predict(X=test_summary_rf_3)\n\nprint(pd.Series(metrics_rf_3['train']).mean())\nprint(pd.Series(metrics_rf_3['val']).mean())\nprint(balanced_logloss_np(y_true=train_out['Class'].values,y_pred=train_out['Class_RF'].values))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:52:39.674849Z","iopub.execute_input":"2023-07-22T07:52:39.675348Z","iopub.status.idle":"2023-07-22T07:52:39.689348Z","shell.execute_reply.started":"2023-07-22T07:52:39.675309Z","shell.execute_reply":"2023-07-22T07:52:39.687879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out['Class_GBT'] = gbt_ensemble.predict(X=train_summary_gbt_2)\ntest_out['Class_GBT'] = gbt_ensemble.predict(X=test_summary_gbt_2)\n\nprint(pd.Series(metrics_gbt_2['train']).mean())\nprint(pd.Series(metrics_gbt_2['val']).mean())\nprint(balanced_logloss_np(y_true=train_out['Class'].values,y_pred=train_out['Class_GBT'].values))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:52:40.501860Z","iopub.execute_input":"2023-07-22T07:52:40.502785Z","iopub.status.idle":"2023-07-22T07:52:40.516654Z","shell.execute_reply.started":"2023-07-22T07:52:40.502747Z","shell.execute_reply":"2023-07-22T07:52:40.515227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out['Class_TABPFN'] = tabpfn_ensemble.predict(X=train_summary_tabpfn_1)\ntest_out['Class_TABPFN'] = tabpfn_ensemble.predict(X=test_summary_tabpfn_1)\n\nprint(pd.Series(metrics_tabpfn_2['train']).mean())\nprint(pd.Series(metrics_tabpfn_2['val']).mean())\nprint(balanced_logloss_np(y_true=train_out['Class'].values,y_pred=train_out['Class_TABPFN'].values))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:53:01.580168Z","iopub.execute_input":"2023-07-22T07:53:01.580711Z","iopub.status.idle":"2023-07-22T07:53:01.594860Z","shell.execute_reply.started":"2023-07-22T07:53:01.580672Z","shell.execute_reply":"2023-07-22T07:53:01.593705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble Classes","metadata":{}},{"cell_type":"markdown","source":"I can for example use GBT","metadata":{}},{"cell_type":"code","source":"train_out[['Class_RF','Class_GBT','Class_TABPFN','Class']].corr()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:53:04.251819Z","iopub.execute_input":"2023-07-22T07:53:04.252606Z","iopub.status.idle":"2023-07-22T07:53:04.268921Z","shell.execute_reply.started":"2023-07-22T07:53:04.252566Z","shell.execute_reply":"2023-07-22T07:53:04.267406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GradientBoostedTreesModel\n# Got Very Bas score up to 1.5 in LB\n# train_summary_gbt_3, valid_summary_gbt_3, test_summary_gbt_3, model_gbt_3,metrics_gbt_3 = train_model(\n#     train=train_out,test=test_out, features=['Class_RF','Class_GBT','Class_TABPFN'],                                             \n#     n_splits=10,                    \n#     model_obj=tfdf.keras.GradientBoostedTreesModel,            \n#     model_kwargs=dict(max_depth=2, num_trees=1000),                                                  \n#     model_compile_kwargs=dict(metrics=[metrics.binary_accuracy, BalancedLogLoss()]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:49:11.787044Z","iopub.execute_input":"2023-07-22T07:49:11.787580Z","iopub.status.idle":"2023-07-22T07:49:11.793938Z","shell.execute_reply.started":"2023-07-22T07:49:11.787542Z","shell.execute_reply":"2023-07-22T07:49:11.792500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF_w = 2.5/10\nGBT_w = 4.5/10\nTabPFN_w = 3./10\n\nprint('RF weight: ', RF_w)\nprint('GBT weight: ', GBT_w)\nprint('TabPFN weight: ', TabPFN_w)\n\nsubmition_total = test_out[['Class_RF','Class_GBT','Class_TABPFN']].copy()\nsubmition_total.columns = ['RF','GBT','TabPFN']\n\nsubmition_total['Ensemble'] = RF_w*submition_total['RF'] + GBT_w*submition_total['GBT'] + TabPFN_w*submition_total['TabPFN']\n\nsubmition_total.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:57:39.915443Z","iopub.execute_input":"2023-07-22T07:57:39.915856Z","iopub.status.idle":"2023-07-22T07:57:39.936041Z","shell.execute_reply.started":"2023-07-22T07:57:39.915827Z","shell.execute_reply":"2023-07-22T07:57:39.934959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# submition_total\nsubmition_total['Ensemble'] = np.where(submition_total['Ensemble']>0.95,1,submition_total['Ensemble'])\nsubmition_total['Ensemble'] = np.where(submition_total['Ensemble']<0.05,0,submition_total['Ensemble'])\nsubmition_total['class_1'] = submition_total['Ensemble']\nsubmition_total['class_0'] = 1 - submition_total['class_1']\nsubmition_total = submition_total[['class_0','class_1']].copy()\nsubmition_total.to_csv('/kaggle/working/submission.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:57:42.904140Z","iopub.execute_input":"2023-07-22T07:57:42.905178Z","iopub.status.idle":"2023-07-22T07:57:42.917128Z","shell.execute_reply.started":"2023-07-22T07:57:42.905108Z","shell.execute_reply":"2023-07-22T07:57:42.916023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition_total.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:57:47.498228Z","iopub.execute_input":"2023-07-22T07:57:47.498695Z","iopub.status.idle":"2023-07-22T07:57:47.512824Z","shell.execute_reply.started":"2023-07-22T07:57:47.498654Z","shell.execute_reply":"2023-07-22T07:57:47.511205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition_total.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:57:53.687490Z","iopub.execute_input":"2023-07-22T07:57:53.687928Z","iopub.status.idle":"2023-07-22T07:57:53.704897Z","shell.execute_reply.started":"2023-07-22T07:57:53.687897Z","shell.execute_reply":"2023-07-22T07:57:53.703952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}