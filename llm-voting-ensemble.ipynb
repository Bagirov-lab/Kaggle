{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8754deee",
   "metadata": {
    "papermill": {
     "duration": 0.007366,
     "end_time": "2023-08-11T15:06:08.940991",
     "exception": false,
     "start_time": "2023-08-11T15:06:08.933625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97886958",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-11T15:06:08.957205Z",
     "iopub.status.busy": "2023-08-11T15:06:08.956444Z",
     "iopub.status.idle": "2023-08-11T15:06:22.871816Z",
     "shell.execute_reply": "2023-08-11T15:06:22.870832Z"
    },
    "papermill": {
     "duration": 13.926102,
     "end_time": "2023-08-11T15:06:22.874231",
     "exception": false,
     "start_time": "2023-08-11T15:06:08.948129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "deberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c380df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T09:27:23.457365Z",
     "iopub.status.busy": "2023-08-05T09:27:23.456463Z",
     "iopub.status.idle": "2023-08-05T09:27:23.461605Z",
     "shell.execute_reply": "2023-08-05T09:27:23.460469Z",
     "shell.execute_reply.started": "2023-08-05T09:27:23.457331Z"
    },
    "papermill": {
     "duration": 0.00681,
     "end_time": "2023-08-11T15:06:22.888260",
     "exception": false,
     "start_time": "2023-08-11T15:06:22.881450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578c1b82",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-11T15:06:22.903557Z",
     "iopub.status.busy": "2023-08-11T15:06:22.903215Z",
     "iopub.status.idle": "2023-08-11T15:06:22.916220Z",
     "shell.execute_reply": "2023-08-11T15:06:22.915323Z"
    },
    "papermill": {
     "duration": 0.023364,
     "end_time": "2023-08-11T15:06:22.918446",
     "exception": false,
     "start_time": "2023-08-11T15:06:22.895082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    second_sentences = [example[option] for option in 'ABCDE']\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=False)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    \n",
    "    return tokenized_example\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64bc1006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:06:22.933815Z",
     "iopub.status.busy": "2023-08-11T15:06:22.933512Z",
     "iopub.status.idle": "2023-08-11T15:06:24.464573Z",
     "shell.execute_reply": "2023-08-11T15:06:24.463610Z"
    },
    "papermill": {
     "duration": 1.541466,
     "end_time": "2023-08-11T15:06:24.466954",
     "exception": false,
     "start_time": "2023-08-11T15:06:22.925488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0dc0a0ed1a47a59a60cc1c4ea8e423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\n",
    "test_df['answer'] = 'A' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\n",
    "\n",
    "tokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, 10, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beccb8eb",
   "metadata": {
    "papermill": {
     "duration": 0.007114,
     "end_time": "2023-08-11T15:06:24.481800",
     "exception": false,
     "start_time": "2023-08-11T15:06:24.474686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc2923",
   "metadata": {
    "papermill": {
     "duration": 0.006976,
     "end_time": "2023-08-11T15:06:24.496114",
     "exception": false,
     "start_time": "2023-08-11T15:06:24.489138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will do 3 iterations through the test set, at every iteration loading model weights I uploaded from a different training run and performing inference as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3262b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:06:24.511782Z",
     "iopub.status.busy": "2023-08-11T15:06:24.511476Z",
     "iopub.status.idle": "2023-08-11T15:08:04.079480Z",
     "shell.execute_reply": "2023-08-11T15:08:04.078547Z"
    },
    "papermill": {
     "duration": 99.586084,
     "end_time": "2023-08-11T15:08:04.089359",
     "exception": false,
     "start_time": "2023-08-11T15:06:24.503275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 s, sys: 7.06 s, total: 55.2 s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_preds_my_runs = []\n",
    "for i in range(3):\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/science-exam-trained-model-weights/run_{i}').cuda()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for batch in test_dataloader:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        preds.append(outputs.logits.cpu().detach())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    all_preds_my_runs.append(preds)\n",
    "\n",
    "all_preds_my_runs = torch.stack(all_preds_my_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048f132",
   "metadata": {
    "papermill": {
     "duration": 0.007085,
     "end_time": "2023-08-11T15:08:04.103814",
     "exception": false,
     "start_time": "2023-08-11T15:08:04.096729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let us predict using the weights shared by `Hyc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3622d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:04.120563Z",
     "iopub.status.busy": "2023-08-11T15:08:04.119711Z",
     "iopub.status.idle": "2023-08-11T15:08:33.163916Z",
     "shell.execute_reply": "2023-08-11T15:08:33.162896Z"
    },
    "papermill": {
     "duration": 29.055587,
     "end_time": "2023-08-11T15:08:33.166962",
     "exception": false,
     "start_time": "2023-08-11T15:08:04.111375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/2023kagglellm-deberta-v3-large-model1').cuda()\n",
    "model.eval()\n",
    "preds = []\n",
    "for batch in test_dataloader:\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    preds.append(outputs.logits.cpu().detach())\n",
    "\n",
    "hyc_preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264fdd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.183834Z",
     "iopub.status.busy": "2023-08-11T15:08:33.183535Z",
     "iopub.status.idle": "2023-08-11T15:08:33.190292Z",
     "shell.execute_reply": "2023-08-11T15:08:33.189434Z"
    },
    "papermill": {
     "duration": 0.017324,
     "end_time": "2023-08-11T15:08:33.192246",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.174922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 200, 5]), torch.Size([200, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_my_runs.shape, hyc_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2e1b3",
   "metadata": {
    "papermill": {
     "duration": 0.007263,
     "end_time": "2023-08-11T15:08:33.207202",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.199939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74577505",
   "metadata": {
    "papermill": {
     "duration": 0.0073,
     "end_time": "2023-08-11T15:08:33.222362",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.215062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us now combine the predictions with the `voting ensemble` approach.\n",
    "\n",
    "`hyc_preds` achieve a higher score on the LB. I will want my models to overrule `hyc_preds` only if they all agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a827d05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.238699Z",
     "iopub.status.busy": "2023-08-11T15:08:33.238358Z",
     "iopub.status.idle": "2023-08-11T15:08:33.258933Z",
     "shell.execute_reply": "2023-08-11T15:08:33.258057Z"
    },
    "papermill": {
     "duration": 0.031263,
     "end_time": "2023-08-11T15:08:33.261061",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.229798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "voting_ensemble = defaultdict(list)\n",
    "\n",
    "for i_preds in range(all_preds_my_runs.shape[0]):\n",
    "    for row in range(all_preds_my_runs.shape[1]):\n",
    "        preds = all_preds_my_runs[i_preds][row]\n",
    "        voting_ensemble[row].append(preds.argsort(descending=True)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a76c454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.277542Z",
     "iopub.status.busy": "2023-08-11T15:08:33.276857Z",
     "iopub.status.idle": "2023-08-11T15:08:33.285015Z",
     "shell.execute_reply": "2023-08-11T15:08:33.284190Z"
    },
    "papermill": {
     "duration": 0.018459,
     "end_time": "2023-08-11T15:08:33.287015",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.268556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in range(hyc_preds.shape[0]):\n",
    "    preds = hyc_preds[row]\n",
    "    voting_ensemble[row].append(preds.argsort(descending=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403d056",
   "metadata": {
    "papermill": {
     "duration": 0.007195,
     "end_time": "2023-08-11T15:08:33.301912",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.294717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For each example in the test set, we now have the top 3 predicted answers from each of our models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de2152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T23:49:16.845465Z",
     "iopub.status.busy": "2023-08-07T23:49:16.845107Z",
     "iopub.status.idle": "2023-08-07T23:49:16.856705Z",
     "shell.execute_reply": "2023-08-07T23:49:16.855197Z",
     "shell.execute_reply.started": "2023-08-07T23:49:16.845435Z"
    },
    "papermill": {
     "duration": 0.007163,
     "end_time": "2023-08-11T15:08:33.316644",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.309481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us now combine the votes, giving more weight to the predictions from `hyc_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d93b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.333147Z",
     "iopub.status.busy": "2023-08-11T15:08:33.332409Z",
     "iopub.status.idle": "2023-08-11T15:08:33.352174Z",
     "shell.execute_reply": "2023-08-11T15:08:33.351343Z"
    },
    "papermill": {
     "duration": 0.030123,
     "end_time": "2023-08-11T15:08:33.354143",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.324020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i_preds in range(all_preds_my_runs.shape[1]):\n",
    "    votes = defaultdict(lambda: 0)\n",
    "    for preds in voting_ensemble[i_preds][:3]:\n",
    "        votes[preds[0].item()] += 3\n",
    "        votes[preds[1].item()] += 2\n",
    "        votes[preds[2].item()] += 1\n",
    "    hyc_preds = voting_ensemble[i_preds][3]\n",
    "    votes[hyc_preds[0].item()] += 3 * 3.1 # never unseat top prediction by `hyc_weights` even with 3,3,3 from my weights\n",
    "    votes[hyc_preds[1].item()] += 2 * 2.9 \n",
    "    votes[hyc_preds[2].item()] += 1 * 2.9 \n",
    "        \n",
    "    predictions.append([t[0] for t in sorted(votes.items(), key=lambda x:x[1], reverse=True)][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72f147",
   "metadata": {
    "papermill": {
     "duration": 0.007217,
     "end_time": "2023-08-11T15:08:33.368804",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.361587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have carried out the \"voting\", let us combine the predictions from the `voting ensemble` in to a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4fd817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.385270Z",
     "iopub.status.busy": "2023-08-11T15:08:33.384443Z",
     "iopub.status.idle": "2023-08-11T15:08:33.391112Z",
     "shell.execute_reply": "2023-08-11T15:08:33.390159Z"
    },
    "papermill": {
     "duration": 0.016969,
     "end_time": "2023-08-11T15:08:33.393133",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.376164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 2], [0, 2, 3], [0, 2, 3], [2, 1, 0], [1, 0, 3]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a070482",
   "metadata": {
    "papermill": {
     "duration": 0.007526,
     "end_time": "2023-08-11T15:08:33.408244",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.400718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341548c7",
   "metadata": {
    "papermill": {
     "duration": 0.007258,
     "end_time": "2023-08-11T15:08:33.423109",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.415851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us now assign a letter corresponding to each predicted id (0 -> 'A', 1 -> 'B', etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdfdc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.439937Z",
     "iopub.status.busy": "2023-08-11T15:08:33.439092Z",
     "iopub.status.idle": "2023-08-11T15:08:33.446040Z",
     "shell.execute_reply": "2023-08-11T15:08:33.445076Z"
    },
    "papermill": {
     "duration": 0.017275,
     "end_time": "2023-08-11T15:08:33.448026",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.430751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['D', 'B', 'C'],\n",
       "       ['A', 'C', 'D'],\n",
       "       ['A', 'C', 'D']], dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions]\n",
    "predictions_as_answer_letters[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65da7e",
   "metadata": {
    "papermill": {
     "duration": 0.008223,
     "end_time": "2023-08-11T15:08:33.463933",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.455710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And let us now go from this representation to outputting a string with 3 highest rated answers seperated by a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b85d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.481410Z",
     "iopub.status.busy": "2023-08-11T15:08:33.480522Z",
     "iopub.status.idle": "2023-08-11T15:08:33.488709Z",
     "shell.execute_reply": "2023-08-11T15:08:33.487792Z"
    },
    "papermill": {
     "duration": 0.018704,
     "end_time": "2023-08-11T15:08:33.490699",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.471995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D B C', 'A C D', 'A C D']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_string = test_df['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]\n",
    "predictions_as_string[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db3228",
   "metadata": {
    "papermill": {
     "duration": 0.007601,
     "end_time": "2023-08-11T15:08:33.506140",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.498539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And we are done! 🥳\n",
    "\n",
    "Let us now output our submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e365f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:08:33.524205Z",
     "iopub.status.busy": "2023-08-11T15:08:33.523278Z",
     "iopub.status.idle": "2023-08-11T15:08:33.544353Z",
     "shell.execute_reply": "2023-08-11T15:08:33.543384Z"
    },
    "papermill": {
     "duration": 0.032198,
     "end_time": "2023-08-11T15:08:33.546439",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.514241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B A D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id prediction\n",
       "0   0      D B C\n",
       "1   1      A C D\n",
       "2   2      A C D\n",
       "3   3      C B A\n",
       "4   4      B A D"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test_df[['id', 'prediction']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "pd.read_csv('submission.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc67dc",
   "metadata": {
    "papermill": {
     "duration": 0.007755,
     "end_time": "2023-08-11T15:08:33.562889",
     "exception": false,
     "start_time": "2023-08-11T15:08:33.555134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I hope you enjoyed this notebook!\n",
    "\n",
    "**If you found this useful, please upvote 👉 [dataset where I share the weights from the trained models](https://www.kaggle.com/datasets/radek1/science-exam-trained-model-weights) 👈**\n",
    "\n",
    "Thank you, appreciate your help! 🙏😊\n",
    "\n",
    "Thank you for reading and happy Kaggling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 157.750173,
   "end_time": "2023-08-11T15:08:36.878617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-11T15:05:59.128444",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "059906ed37aa45a6a9fa0a70ac97e77c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0e0dc0a0ed1a47a59a60cc1c4ea8e423": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97a9c381f7474a30a58d3f4f026f0f27",
        "IPY_MODEL_77c271d4a39243889171702188e10462",
        "IPY_MODEL_c97815182b69476eb9e54825885d5ce8"
       ],
       "layout": "IPY_MODEL_8d07d1a13f394147bc2973e0a020f760"
      }
     },
     "13986d2b756141238fe32b49ba168e59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3d073e4a2c604662b8d03bd20358739d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51845cef359f49878534a7141b195e5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77c271d4a39243889171702188e10462": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_51845cef359f49878534a7141b195e5f",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_059906ed37aa45a6a9fa0a70ac97e77c",
       "value": 200.0
      }
     },
     "7dda270d26ba4e229dcf177e00924404": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8d07d1a13f394147bc2973e0a020f760": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97a9c381f7474a30a58d3f4f026f0f27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3d073e4a2c604662b8d03bd20358739d",
       "placeholder": "​",
       "style": "IPY_MODEL_7dda270d26ba4e229dcf177e00924404",
       "value": "100%"
      }
     },
     "c97815182b69476eb9e54825885d5ce8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f485b12e2ae84da4ba56b6383069de6d",
       "placeholder": "​",
       "style": "IPY_MODEL_13986d2b756141238fe32b49ba168e59",
       "value": " 200/200 [00:00&lt;00:00, 825.71ex/s]"
      }
     },
     "f485b12e2ae84da4ba56b6383069de6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
