{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0481112f",
   "metadata": {
    "papermill": {
     "duration": 0.007143,
     "end_time": "2023-08-02T14:52:33.289685",
     "exception": false,
     "start_time": "2023-08-02T14:52:33.282542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630be7a6",
   "metadata": {
    "papermill": {
     "duration": 0.006241,
     "end_time": "2023-08-02T14:52:33.302540",
     "exception": false,
     "start_time": "2023-08-02T14:52:33.296299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Research applicability of XGBoost package.\n",
    "\n",
    "TODO:\n",
    "- [x] Shall add Cut Offs\n",
    "- [ ] Shall One model version based on CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3044df",
   "metadata": {
    "papermill": {
     "duration": 0.005986,
     "end_time": "2023-08-02T14:52:33.315069",
     "exception": false,
     "start_time": "2023-08-02T14:52:33.309083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2a26c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:33.329965Z",
     "iopub.status.busy": "2023-08-02T14:52:33.329433Z",
     "iopub.status.idle": "2023-08-02T14:52:35.213329Z",
     "shell.execute_reply": "2023-08-02T14:52:35.212126Z"
    },
    "papermill": {
     "duration": 1.895034,
     "end_time": "2023-08-02T14:52:35.216346",
     "exception": false,
     "start_time": "2023-08-02T14:52:33.321312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from woe_utils import WOENumericalComplex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037412fd",
   "metadata": {
    "papermill": {
     "duration": 0.006195,
     "end_time": "2023-08-02T14:52:35.229124",
     "exception": false,
     "start_time": "2023-08-02T14:52:35.222929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Standard Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6396b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:35.243837Z",
     "iopub.status.busy": "2023-08-02T14:52:35.243417Z",
     "iopub.status.idle": "2023-08-02T14:52:46.465108Z",
     "shell.execute_reply": "2023-08-02T14:52:46.463817Z"
    },
    "papermill": {
     "duration": 11.232404,
     "end_time": "2023-08-02T14:52:46.467884",
     "exception": false,
     "start_time": "2023-08-02T14:52:35.235480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "from keras import metrics # accuracy\n",
    "from keras import backend as K\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator \n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, DMatrix\n",
    "\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cf0c3",
   "metadata": {
    "papermill": {
     "duration": 0.006458,
     "end_time": "2023-08-02T14:52:46.482543",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.476085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7867a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:46.499608Z",
     "iopub.status.busy": "2023-08-02T14:52:46.497711Z",
     "iopub.status.idle": "2023-08-02T14:52:46.560539Z",
     "shell.execute_reply": "2023-08-02T14:52:46.559153Z"
    },
    "papermill": {
     "duration": 0.074476,
     "end_time": "2023-08-02T14:52:46.563647",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.489171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.read_pickle('/kaggle/input/invitro-train-feature-engineer/features.pickle')\n",
    "test = pd.read_pickle('/kaggle/input/invitro-train-feature-engineer/test_processed.pickle')\n",
    "train = pd.read_pickle('/kaggle/input/invitro-train-feature-engineer/train_processed.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3f606",
   "metadata": {
    "papermill": {
     "duration": 0.006805,
     "end_time": "2023-08-02T14:52:46.577886",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.571081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Model\n",
    "\n",
    "Today, we will use the defaults to create the Random Forest Model. By default the model is set to train for a classification task.\n",
    "We will train a model for each fold and after training we will store the model and metrics. Here, we have chosen `accuracy` and `binary_crossentropy` as the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7bc85",
   "metadata": {
    "papermill": {
     "duration": 0.006582,
     "end_time": "2023-08-02T14:52:46.591484",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.584902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b88b01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:46.607826Z",
     "iopub.status.busy": "2023-08-02T14:52:46.607135Z",
     "iopub.status.idle": "2023-08-02T14:52:46.659230Z",
     "shell.execute_reply": "2023-08-02T14:52:46.658037Z"
    },
    "papermill": {
     "duration": 0.064001,
     "end_time": "2023-08-02T14:52:46.662475",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.598474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BalancedLogLoss(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='balanced_log_loss', **kwargs):\n",
    "        super(BalancedLogLoss, self).__init__(name=name, **kwargs)\n",
    "        self.log_loss = self.add_weight(name='log_loss', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true: tf.Tensor, y_pred: tf.Tensor, sample_weight=None):\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        # Correct Values\n",
    "        min_val = 1e-15\n",
    "        max_val = 0.999999999999999\n",
    "        \n",
    "        y_pred = tf.math.minimum(y_pred, [max_val])\n",
    "        y_pred = tf.math.maximum(y_pred, [min_val])\n",
    "        \n",
    "        log_y_pred_1 = tf.reshape(K.log(y_pred),[-1,1])\n",
    "        log_y_pred_0 = tf.reshape(K.log(1-y_pred),[-1,1])\n",
    "\n",
    "        y_1 = tf.reshape(y_true,[1,-1])\n",
    "        y_0 = 1-y_1\n",
    "\n",
    "        logloss_1 = -K.dot(y_1,log_y_pred_1)[0][0]/K.sum(y_1)\n",
    "        logloss_0 = -K.dot(y_0,log_y_pred_0)[0][0]/K.sum(y_0)\n",
    "\n",
    "        av_logloss = (logloss_1+logloss_0)/2\n",
    "        \n",
    "        self.log_loss.assign_add(av_logloss)\n",
    "\n",
    "    def result(self):\n",
    "        return self.log_loss\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.log_loss.assign(0.)\n",
    "        \n",
    "def balanced_logloss_np(y_true: np.array, y_pred: np.array) -> float:\n",
    "    \n",
    "    # Correct Values\n",
    "    min_val = 1e-15\n",
    "    max_val = 0.999999999999999\n",
    "\n",
    "    y_pred = np.minimum(y_pred, [max_val])\n",
    "    y_pred = np.maximum(y_pred, [min_val])\n",
    "    \n",
    "    y_pred_1 = y_pred\n",
    "    y_pred_0 = 1-y_pred\n",
    "\n",
    "    log_y_pred_1 = np.reshape(np.log(y_pred_1),[-1,1])\n",
    "    log_y_pred_0 = np.reshape(np.log(y_pred_0),[-1,1])\n",
    "\n",
    "    y_1 = np.reshape(y_true,[1,-1])\n",
    "    y_0 = (y_1-1)*(-1)\n",
    "\n",
    "    logloss_1 = -np.dot(y_1,log_y_pred_1)[0][0]/np.sum(y_1)\n",
    "    logloss_0 = -np.dot(y_0,log_y_pred_0)[0][0]/np.sum(y_0)\n",
    "\n",
    "    av_logloss = (logloss_1+logloss_0)/2\n",
    "    \n",
    "    return av_logloss\n",
    "\n",
    "def plot_train_logs(model) -> None:\n",
    "\n",
    "    logs = model.make_inspector().training_logs()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "    plt.xlabel(\"Number of trees\")\n",
    "    plt.ylabel(\"Accuracy (out-of-bag)\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
    "    plt.xlabel(\"Number of trees\")\n",
    "    plt.ylabel(\"Logloss (out-of-bag)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "class XGB_CV_Ensemble(RegressorMixin,BaseEstimator):\n",
    "    def __init__(self, model_obj = XGBClassifier, label = \"Class\", predict_func = np.mean):\n",
    "        self.label: str = label\n",
    "        self.model_obj = model_obj\n",
    "        \n",
    "        # Empty\n",
    "        self.X_summary: pd.DataFrame = pd.DataFrame()\n",
    "        self.valid_summary: pd.DataFrame = pd.DataFrame()\n",
    "        self.features: list = list()\n",
    "        self.models: dict = dict()\n",
    "        self.metrics: dict = dict()\n",
    "        self.predict_func = predict_func\n",
    "        self.cut_off_lower: float = 0.5\n",
    "        self.cut_off_upper: float = 0.5\n",
    "        self.cut_off: float = 0.5\n",
    "        \n",
    "    def _compute_weights(self, df: pd.DataFrame) -> dict:\n",
    "        # Calculate the number of samples for each label.\n",
    "        neg, pos = np.bincount(df[self.label])\n",
    "        total = neg + pos\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "        return class_weight\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, features: list, splitter = StratifiedKFold(),\n",
    "            model_kwargs = dict()):\n",
    "\n",
    "        n_splits = splitter.get_n_splits()\n",
    "\n",
    "        # Create a various frames\n",
    "        self.X_summary = pd.DataFrame(data=np.full((len(X.index),n_splits), np.nan), index=X.index) # For In-Sample Predictions of each Fold\n",
    "        self.valid_summary = pd.DataFrame(data=np.full((len(X.index),1), np.nan), index=X.index) # For Out-of-Sample Prediction of each Fold\n",
    "        self.features: list = features\n",
    "        \n",
    "        # Create an empty dictionary to store the models Xed for each fold.\n",
    "        self.models = {}\n",
    "        self.metrics = {}\n",
    "        balanced_logloss_train = {}\n",
    "        balanced_logloss_val = {}\n",
    "\n",
    "        class_weight: dict = self._compute_weights(X)\n",
    "        \n",
    "        for i, (train_index, valid_index) in enumerate(splitter.split(X=X,y=X['Class'])):\n",
    "                print('##### Fold',i+1)\n",
    "\n",
    "                # Fetch values corresponding to the index \n",
    "                train_df = X.iloc[train_index]\n",
    "                valid_df = X.iloc[valid_index]\n",
    "                valid_ids = valid_df.index.values\n",
    "                train_ids = train_df.index.values\n",
    "\n",
    "                # Select only feature columns for training.\n",
    "                train_df = train_df[self.features+[self.label]]\n",
    "                valid_df = valid_df[self.features+[self.label]]\n",
    "\n",
    "                # Define & Train the model and metrics\n",
    "                model = self.model_obj(**model_kwargs)\n",
    "                model.fit(X=train_df[self.features], y=train_df[self.label])\n",
    "\n",
    "                # Store the model\n",
    "                self.models[i] = model\n",
    "\n",
    "                # Predict Values\n",
    "                y_pred_train = model.predict_proba(X=train_df[self.features])[:,1]\n",
    "                y_pred_valid = model.predict_proba(X=valid_df[self.features])[:,1]\n",
    "                y_true_train = train_df[self.label].values\n",
    "                y_true_valid = valid_df[self.label].values\n",
    "                \n",
    "                self.X_summary.loc[train_ids, i] = y_pred_train\n",
    "                self.X_summary.loc[valid_ids, i] = y_pred_valid\n",
    "                self.valid_summary.loc[valid_ids, 0] = y_pred_valid\n",
    "\n",
    "                # Evaluate and store the metrics in respective dicts\n",
    "                train_metric = balanced_logloss_np(y_pred=y_pred_train, y_true=y_true_train)\n",
    "                val_metric = balanced_logloss_np(y_pred=y_pred_valid, y_true=y_true_valid)\n",
    "\n",
    "                # Plot Results\n",
    "#                 plot_train_logs(model)\n",
    "\n",
    "                balanced_logloss_train[i] = train_metric\n",
    "                balanced_logloss_val[i] = val_metric\n",
    "\n",
    "                print(f\"\\nTrain: {train_metric:.4f} Validation: {val_metric:.4f}\")\n",
    "\n",
    "        self.metrics['train'] = balanced_logloss_train\n",
    "        self.metrics['val'] = balanced_logloss_val\n",
    "\n",
    "        print(f\"\\nTrain mean: {pd.Series(self.metrics['train']).mean():.4f} std: {pd.Series(self.metrics['train']).std():.4f}\")\n",
    "        print(f\"\\nValidation mean: {pd.Series(self.metrics['val']).mean():.4f} std: {pd.Series(self.metrics['val']).std():.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_cut_offs(self, lower: float, upper: float):\n",
    "        \n",
    "        self.cut_off_lower: float = lower\n",
    "        self.cut_off_upper: float = upper\n",
    "\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame, use_cut_offs: bool = True) -> pd.Series:\n",
    "        n_splits = len(self.models)\n",
    "        y_probas = pd.DataFrame(data=np.full((len(X.index),n_splits), np.nan),index=X.index) # For X (Sumbition) Predictions of each Fold's Model\n",
    "\n",
    "        for i, model in enumerate(self.models.values()):\n",
    "            y_probas[i] = model.predict_proba(X=X[self.features])[:,1] \n",
    "        \n",
    "        y_proba: pd.Series = self.predict_func(y_probas, axis=1)\n",
    "            \n",
    "        y_proba.name = 'y_hat'\n",
    "        \n",
    "        # If cut-offs accepted\n",
    "        if use_cut_offs:\n",
    "            # lower\n",
    "            y_proba = np.where(y_proba < self.cut_off_lower, 0, y_proba)\n",
    "            # upper\n",
    "            y_proba = np.where(y_proba > self.cut_off_upper, 1, y_proba)\n",
    "        \n",
    "        return y_proba\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        \n",
    "        # Simple preidctins\n",
    "        y_pred = self.predict_proba(X, use_cut_offs=False)\n",
    "        \n",
    "        # Round by Threshold\n",
    "        y_pred = np.where(y_pred < self.cut_off,0,1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def save(self, save_path: str) -> None:\n",
    "        try:\n",
    "            shutil.rmtree(save_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        os.makedirs(f'{save_path}/models', exist_ok=True)\n",
    "        \n",
    "        for fold, model in self.models.items():\n",
    "            model.save_model(f'{save_path}/models/{fold}')\n",
    "        \n",
    "        joblib.dump(value=self.label, filename=f'{save_path}/label.pickle')\n",
    "        joblib.dump(value=self.model_obj, filename=f'{save_path}/model_obj.pickle')\n",
    "        \n",
    "        joblib.dump(value=self.X_summary, filename=f'{save_path}/X_summary.pickle')\n",
    "        joblib.dump(value=self.valid_summary, filename=f'{save_path}/valid_summary.pickle')\n",
    "        joblib.dump(value=self.features, filename=f'{save_path}/features.pickle')\n",
    "        joblib.dump(value=self.metrics, filename=f'{save_path}/metrics.pickle')\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def load(self, save_path: str):\n",
    "        \n",
    "        self.label = joblib.load(filename=f'{save_path}/label.pickle')\n",
    "        self.model_obj = joblib.load(filename=f'{save_path}/model_obj.pickle')\n",
    "        \n",
    "        self.X_summary = joblib.load(filename=f'{save_path}/X_summary.pickle')\n",
    "        self.valid_summary = joblib.load(filename=f'{save_path}/valid_summary.pickle')\n",
    "        self.features = joblib.load(filename=f'{save_path}/features.pickle')\n",
    "        self.metrics = joblib.load(filename=f'{save_path}/metrics.pickle')\n",
    "        \n",
    "        self.models = dict()\n",
    "        \n",
    "        for name in os.listdir(f'{save_path}/models'):\n",
    "            i = name.split('.')[0]\n",
    "            self.models[int(i)] = tf.keras.models.load_model(f'{save_path}/models/{i}',\n",
    "                                              custom_objects={\"BalancedLogLoss\": BalancedLogLoss})\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dd358",
   "metadata": {
    "papermill": {
     "duration": 0.007122,
     "end_time": "2023-08-02T14:52:46.676803",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.669681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e57ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:46.692912Z",
     "iopub.status.busy": "2023-08-02T14:52:46.692222Z",
     "iopub.status.idle": "2023-08-02T14:52:48.385024Z",
     "shell.execute_reply": "2023-08-02T14:52:48.384062Z"
    },
    "papermill": {
     "duration": 1.703743,
     "end_time": "2023-08-02T14:52:48.387660",
     "exception": false,
     "start_time": "2023-08-02T14:52:46.683917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Fold 1\n",
      "\n",
      "Train: 0.0169 Validation: 0.3197\n",
      "##### Fold 2\n",
      "\n",
      "Train: 0.0165 Validation: 0.3352\n",
      "##### Fold 3\n",
      "\n",
      "Train: 0.0177 Validation: 0.3826\n",
      "##### Fold 4\n",
      "\n",
      "Train: 0.0175 Validation: 0.3242\n",
      "##### Fold 5\n",
      "\n",
      "Train: 0.0157 Validation: 0.4855\n",
      "##### Fold 6\n",
      "\n",
      "Train: 0.0163 Validation: 0.5578\n",
      "\n",
      "Train mean: 0.0168 std: 0.0008\n",
      "\n",
      "Validation mean: 0.4008 std: 0.0989\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85, verbosity=1)\n",
    "\n",
    "# Test\n",
    "my_splitter = StratifiedKFold(n_splits=6,shuffle=True, random_state=1902)\n",
    "\n",
    "# initialise\n",
    "CV_Ensemble_1 = XGB_CV_Ensemble(model_obj=XGBClassifier, label=\"Class\")\n",
    "\n",
    "# train\n",
    "CV_Ensemble_1 = CV_Ensemble_1.fit(X=train, features=features, \n",
    "                                  splitter=my_splitter,\n",
    "                                  model_kwargs=dict(\n",
    "                                      n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,\n",
    "                                      colsample_bytree=0.85, verbosity=1)\n",
    "                                       )\n",
    "\n",
    "# save\n",
    "CV_Ensemble_1.save(save_path='/kaggle/working/XGB/1')\n",
    "\n",
    "# train_summary_rf_3, valid_summary_rf_3, test_summary_rf_3, model_rf_3,metrics_rf_3 \n",
    "\n",
    "# train_summary_rf_1 = CV_Ensemble_1.X_summary\n",
    "# valid_summary_rf_1 = CV_Ensemble_1.valid_summary\n",
    "# test_summary_rf_1 = CV_Ensemble_1.predict_proba(X=test_out, use_cut_offs=False)\n",
    "# model_rf_1 = CV_Ensemble_1.models\n",
    "# metrics_rf_1 = CV_Ensemble_1.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff363e",
   "metadata": {
    "papermill": {
     "duration": 0.007889,
     "end_time": "2023-08-02T14:52:48.403176",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.395287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cut-Offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a3e85f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:48.420357Z",
     "iopub.status.busy": "2023-08-02T14:52:48.419856Z",
     "iopub.status.idle": "2023-08-02T14:52:48.429779Z",
     "shell.execute_reply": "2023-08-02T14:52:48.428207Z"
    },
    "papermill": {
     "duration": 0.021539,
     "end_time": "2023-08-02T14:52:48.432225",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.410686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cut_off(y_pred: pd.Series, y_true: pd.Series) -> pd.DataFrame:\n",
    "    # Let's try to find Cutoffs organically\n",
    "    y_pred.name = 'Pred'\n",
    "    y_true.name = 'Class'\n",
    "\n",
    "    tmp = pd.concat([y_pred, y_true], axis=1).sort_index(ascending=True)\n",
    "\n",
    "    tmp['Pred_Bins'] = pd.qcut(x=tmp['Pred'],q=100)\n",
    "    tmp = tmp.groupby('Pred_Bins')['Class'].agg({'sum','count'})\n",
    "    tmp['count_cumsum'] = tmp['count'].cumsum()\n",
    "    tmp['sum_cumsum'] = tmp['sum'].cumsum()\n",
    "\n",
    "    tmp['bads_rate'] = tmp['sum_cumsum']/tmp['count_cumsum']\n",
    "\n",
    "    tmp['perc_sum'] = [*range(1,101)]\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97eb882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:48.449906Z",
     "iopub.status.busy": "2023-08-02T14:52:48.448959Z",
     "iopub.status.idle": "2023-08-02T14:52:48.604938Z",
     "shell.execute_reply": "2023-08-02T14:52:48.603641Z"
    },
    "papermill": {
     "duration": 0.168017,
     "end_time": "2023-08-02T14:52:48.607741",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.439724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>count_cumsum</th>\n",
       "      <th>sum_cumsum</th>\n",
       "      <th>bads_rate</th>\n",
       "      <th>perc_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_Bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.000903, 0.000138]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000138, 0.000192]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000192, 0.000231]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000231, 0.000276]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000276, 0.000294]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000294, 0.000322]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000322, 0.000349]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000349, 0.00039]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00039, 0.000418]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000418, 0.000453]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000453, 0.000485]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000485, 0.000529]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000529, 0.000576]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000576, 0.000597]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000597, 0.000643]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000643, 0.000655]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000655, 0.000693]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000693, 0.000739]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000739, 0.000772]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000772, 0.000784]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000784, 0.00084]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00084, 0.000911]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000911, 0.000964]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000964, 0.00103]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00103, 0.00107]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00107, 0.00114]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00114, 0.0012]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0012, 0.00123]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00123, 0.0013]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0013, 0.00136]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00136, 0.00138]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00138, 0.00145]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00145, 0.00152]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00152, 0.0016]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0016, 0.00169]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00169, 0.00177]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00177, 0.00187]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00187, 0.00195]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00195, 0.00199]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00199, 0.00201]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00201, 0.00212]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00212, 0.0022]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0022, 0.00231]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00231, 0.00249]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00249, 0.00259]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00259, 0.00265]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00265, 0.00286]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00286, 0.003]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.003, 0.00314]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00314, 0.0032]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0032, 0.00348]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00348, 0.00367]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00367, 0.00387]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00387, 0.00396]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00396, 0.00426]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00426, 0.00443]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00443, 0.00463]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00463, 0.00515]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00515, 0.00561]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00561, 0.00588]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00588, 0.00654]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00654, 0.00693]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00693, 0.00716]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00716, 0.0077]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0077, 0.00874]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00874, 0.00979]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00979, 0.0107]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0107, 0.0111]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0111, 0.0123]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0123, 0.0131]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0131, 0.0144]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0144, 0.0178]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0178, 0.0207]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0207, 0.0234]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0234, 0.0299]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0299, 0.0335]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0335, 0.0408]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0408, 0.0585]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0585, 0.0749]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0749, 0.0845]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0845, 0.137]</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.137, 0.147]</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.147, 0.777]</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.777, 0.806]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>518</td>\n",
       "      <td>9</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.806, 0.836]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>524</td>\n",
       "      <td>15</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.836, 0.851]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>530</td>\n",
       "      <td>21</td>\n",
       "      <td>0.039623</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.851, 0.874]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>536</td>\n",
       "      <td>27</td>\n",
       "      <td>0.050373</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.874, 0.895]</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>543</td>\n",
       "      <td>34</td>\n",
       "      <td>0.062615</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.895, 0.906]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>549</td>\n",
       "      <td>40</td>\n",
       "      <td>0.072860</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.906, 0.919]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>555</td>\n",
       "      <td>46</td>\n",
       "      <td>0.082883</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.919, 0.938]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>561</td>\n",
       "      <td>52</td>\n",
       "      <td>0.092692</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.938, 0.953]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>567</td>\n",
       "      <td>58</td>\n",
       "      <td>0.102293</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.953, 0.964]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>573</td>\n",
       "      <td>64</td>\n",
       "      <td>0.111693</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.964, 0.974]</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>580</td>\n",
       "      <td>71</td>\n",
       "      <td>0.122414</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.974, 0.977]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>586</td>\n",
       "      <td>77</td>\n",
       "      <td>0.131399</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.977, 0.981]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>592</td>\n",
       "      <td>83</td>\n",
       "      <td>0.140203</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.981, 0.988]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>598</td>\n",
       "      <td>89</td>\n",
       "      <td>0.148829</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.988, 0.992]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>604</td>\n",
       "      <td>95</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.992, 0.995]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>610</td>\n",
       "      <td>101</td>\n",
       "      <td>0.165574</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.995, 0.999]</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>617</td>\n",
       "      <td>108</td>\n",
       "      <td>0.175041</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count  sum  count_cumsum  sum_cumsum  bads_rate  \\\n",
       "Pred_Bins                                                                \n",
       "(-0.000903, 0.000138]      7    0             7           0   0.000000   \n",
       "(0.000138, 0.000192]       6    0            13           0   0.000000   \n",
       "(0.000192, 0.000231]       6    0            19           0   0.000000   \n",
       "(0.000231, 0.000276]       6    0            25           0   0.000000   \n",
       "(0.000276, 0.000294]       6    0            31           0   0.000000   \n",
       "(0.000294, 0.000322]       6    0            37           0   0.000000   \n",
       "(0.000322, 0.000349]       7    0            44           0   0.000000   \n",
       "(0.000349, 0.00039]        6    0            50           0   0.000000   \n",
       "(0.00039, 0.000418]        6    0            56           0   0.000000   \n",
       "(0.000418, 0.000453]       6    0            62           0   0.000000   \n",
       "(0.000453, 0.000485]       6    0            68           0   0.000000   \n",
       "(0.000485, 0.000529]       6    0            74           0   0.000000   \n",
       "(0.000529, 0.000576]       7    0            81           0   0.000000   \n",
       "(0.000576, 0.000597]       6    0            87           0   0.000000   \n",
       "(0.000597, 0.000643]       6    0            93           0   0.000000   \n",
       "(0.000643, 0.000655]       6    0            99           0   0.000000   \n",
       "(0.000655, 0.000693]       6    0           105           0   0.000000   \n",
       "(0.000693, 0.000739]       6    0           111           0   0.000000   \n",
       "(0.000739, 0.000772]       7    0           118           0   0.000000   \n",
       "(0.000772, 0.000784]       6    0           124           0   0.000000   \n",
       "(0.000784, 0.00084]        6    0           130           0   0.000000   \n",
       "(0.00084, 0.000911]        6    0           136           0   0.000000   \n",
       "(0.000911, 0.000964]       6    0           142           0   0.000000   \n",
       "(0.000964, 0.00103]        6    0           148           0   0.000000   \n",
       "(0.00103, 0.00107]         7    0           155           0   0.000000   \n",
       "(0.00107, 0.00114]         6    0           161           0   0.000000   \n",
       "(0.00114, 0.0012]          6    0           167           0   0.000000   \n",
       "(0.0012, 0.00123]          6    0           173           0   0.000000   \n",
       "(0.00123, 0.0013]          6    0           179           0   0.000000   \n",
       "(0.0013, 0.00136]          6    0           185           0   0.000000   \n",
       "(0.00136, 0.00138]         6    0           191           0   0.000000   \n",
       "(0.00138, 0.00145]         7    0           198           0   0.000000   \n",
       "(0.00145, 0.00152]         6    0           204           0   0.000000   \n",
       "(0.00152, 0.0016]          6    0           210           0   0.000000   \n",
       "(0.0016, 0.00169]          6    0           216           0   0.000000   \n",
       "(0.00169, 0.00177]         6    0           222           0   0.000000   \n",
       "(0.00177, 0.00187]         6    0           228           0   0.000000   \n",
       "(0.00187, 0.00195]         7    0           235           0   0.000000   \n",
       "(0.00195, 0.00199]         6    0           241           0   0.000000   \n",
       "(0.00199, 0.00201]         6    0           247           0   0.000000   \n",
       "(0.00201, 0.00212]         6    0           253           0   0.000000   \n",
       "(0.00212, 0.0022]          6    0           259           0   0.000000   \n",
       "(0.0022, 0.00231]          6    0           265           0   0.000000   \n",
       "(0.00231, 0.00249]         7    0           272           0   0.000000   \n",
       "(0.00249, 0.00259]         6    0           278           0   0.000000   \n",
       "(0.00259, 0.00265]         6    0           284           0   0.000000   \n",
       "(0.00265, 0.00286]         6    0           290           0   0.000000   \n",
       "(0.00286, 0.003]           6    0           296           0   0.000000   \n",
       "(0.003, 0.00314]           6    0           302           0   0.000000   \n",
       "(0.00314, 0.0032]          7    0           309           0   0.000000   \n",
       "(0.0032, 0.00348]          6    0           315           0   0.000000   \n",
       "(0.00348, 0.00367]         6    0           321           0   0.000000   \n",
       "(0.00367, 0.00387]         6    0           327           0   0.000000   \n",
       "(0.00387, 0.00396]         6    0           333           0   0.000000   \n",
       "(0.00396, 0.00426]         6    0           339           0   0.000000   \n",
       "(0.00426, 0.00443]         6    0           345           0   0.000000   \n",
       "(0.00443, 0.00463]         7    0           352           0   0.000000   \n",
       "(0.00463, 0.00515]         6    0           358           0   0.000000   \n",
       "(0.00515, 0.00561]         6    0           364           0   0.000000   \n",
       "(0.00561, 0.00588]         6    0           370           0   0.000000   \n",
       "(0.00588, 0.00654]         6    0           376           0   0.000000   \n",
       "(0.00654, 0.00693]         6    0           382           0   0.000000   \n",
       "(0.00693, 0.00716]         7    0           389           0   0.000000   \n",
       "(0.00716, 0.0077]          6    0           395           0   0.000000   \n",
       "(0.0077, 0.00874]          6    0           401           0   0.000000   \n",
       "(0.00874, 0.00979]         6    0           407           0   0.000000   \n",
       "(0.00979, 0.0107]          6    0           413           0   0.000000   \n",
       "(0.0107, 0.0111]           6    0           419           0   0.000000   \n",
       "(0.0111, 0.0123]           7    0           426           0   0.000000   \n",
       "(0.0123, 0.0131]           6    0           432           0   0.000000   \n",
       "(0.0131, 0.0144]           6    0           438           0   0.000000   \n",
       "(0.0144, 0.0178]           6    0           444           0   0.000000   \n",
       "(0.0178, 0.0207]           6    0           450           0   0.000000   \n",
       "(0.0207, 0.0234]           6    0           456           0   0.000000   \n",
       "(0.0234, 0.0299]           7    0           463           0   0.000000   \n",
       "(0.0299, 0.0335]           6    0           469           0   0.000000   \n",
       "(0.0335, 0.0408]           6    0           475           0   0.000000   \n",
       "(0.0408, 0.0585]           6    0           481           0   0.000000   \n",
       "(0.0585, 0.0749]           6    0           487           0   0.000000   \n",
       "(0.0749, 0.0845]           6    0           493           0   0.000000   \n",
       "(0.0845, 0.137]            6    0           499           0   0.000000   \n",
       "(0.137, 0.147]             7    0           506           0   0.000000   \n",
       "(0.147, 0.777]             6    3           512           3   0.005859   \n",
       "(0.777, 0.806]             6    6           518           9   0.017375   \n",
       "(0.806, 0.836]             6    6           524          15   0.028626   \n",
       "(0.836, 0.851]             6    6           530          21   0.039623   \n",
       "(0.851, 0.874]             6    6           536          27   0.050373   \n",
       "(0.874, 0.895]             7    7           543          34   0.062615   \n",
       "(0.895, 0.906]             6    6           549          40   0.072860   \n",
       "(0.906, 0.919]             6    6           555          46   0.082883   \n",
       "(0.919, 0.938]             6    6           561          52   0.092692   \n",
       "(0.938, 0.953]             6    6           567          58   0.102293   \n",
       "(0.953, 0.964]             6    6           573          64   0.111693   \n",
       "(0.964, 0.974]             7    7           580          71   0.122414   \n",
       "(0.974, 0.977]             6    6           586          77   0.131399   \n",
       "(0.977, 0.981]             6    6           592          83   0.140203   \n",
       "(0.981, 0.988]             6    6           598          89   0.148829   \n",
       "(0.988, 0.992]             6    6           604          95   0.157285   \n",
       "(0.992, 0.995]             6    6           610         101   0.165574   \n",
       "(0.995, 0.999]             7    7           617         108   0.175041   \n",
       "\n",
       "                       perc_sum  \n",
       "Pred_Bins                        \n",
       "(-0.000903, 0.000138]         1  \n",
       "(0.000138, 0.000192]          2  \n",
       "(0.000192, 0.000231]          3  \n",
       "(0.000231, 0.000276]          4  \n",
       "(0.000276, 0.000294]          5  \n",
       "(0.000294, 0.000322]          6  \n",
       "(0.000322, 0.000349]          7  \n",
       "(0.000349, 0.00039]           8  \n",
       "(0.00039, 0.000418]           9  \n",
       "(0.000418, 0.000453]         10  \n",
       "(0.000453, 0.000485]         11  \n",
       "(0.000485, 0.000529]         12  \n",
       "(0.000529, 0.000576]         13  \n",
       "(0.000576, 0.000597]         14  \n",
       "(0.000597, 0.000643]         15  \n",
       "(0.000643, 0.000655]         16  \n",
       "(0.000655, 0.000693]         17  \n",
       "(0.000693, 0.000739]         18  \n",
       "(0.000739, 0.000772]         19  \n",
       "(0.000772, 0.000784]         20  \n",
       "(0.000784, 0.00084]          21  \n",
       "(0.00084, 0.000911]          22  \n",
       "(0.000911, 0.000964]         23  \n",
       "(0.000964, 0.00103]          24  \n",
       "(0.00103, 0.00107]           25  \n",
       "(0.00107, 0.00114]           26  \n",
       "(0.00114, 0.0012]            27  \n",
       "(0.0012, 0.00123]            28  \n",
       "(0.00123, 0.0013]            29  \n",
       "(0.0013, 0.00136]            30  \n",
       "(0.00136, 0.00138]           31  \n",
       "(0.00138, 0.00145]           32  \n",
       "(0.00145, 0.00152]           33  \n",
       "(0.00152, 0.0016]            34  \n",
       "(0.0016, 0.00169]            35  \n",
       "(0.00169, 0.00177]           36  \n",
       "(0.00177, 0.00187]           37  \n",
       "(0.00187, 0.00195]           38  \n",
       "(0.00195, 0.00199]           39  \n",
       "(0.00199, 0.00201]           40  \n",
       "(0.00201, 0.00212]           41  \n",
       "(0.00212, 0.0022]            42  \n",
       "(0.0022, 0.00231]            43  \n",
       "(0.00231, 0.00249]           44  \n",
       "(0.00249, 0.00259]           45  \n",
       "(0.00259, 0.00265]           46  \n",
       "(0.00265, 0.00286]           47  \n",
       "(0.00286, 0.003]             48  \n",
       "(0.003, 0.00314]             49  \n",
       "(0.00314, 0.0032]            50  \n",
       "(0.0032, 0.00348]            51  \n",
       "(0.00348, 0.00367]           52  \n",
       "(0.00367, 0.00387]           53  \n",
       "(0.00387, 0.00396]           54  \n",
       "(0.00396, 0.00426]           55  \n",
       "(0.00426, 0.00443]           56  \n",
       "(0.00443, 0.00463]           57  \n",
       "(0.00463, 0.00515]           58  \n",
       "(0.00515, 0.00561]           59  \n",
       "(0.00561, 0.00588]           60  \n",
       "(0.00588, 0.00654]           61  \n",
       "(0.00654, 0.00693]           62  \n",
       "(0.00693, 0.00716]           63  \n",
       "(0.00716, 0.0077]            64  \n",
       "(0.0077, 0.00874]            65  \n",
       "(0.00874, 0.00979]           66  \n",
       "(0.00979, 0.0107]            67  \n",
       "(0.0107, 0.0111]             68  \n",
       "(0.0111, 0.0123]             69  \n",
       "(0.0123, 0.0131]             70  \n",
       "(0.0131, 0.0144]             71  \n",
       "(0.0144, 0.0178]             72  \n",
       "(0.0178, 0.0207]             73  \n",
       "(0.0207, 0.0234]             74  \n",
       "(0.0234, 0.0299]             75  \n",
       "(0.0299, 0.0335]             76  \n",
       "(0.0335, 0.0408]             77  \n",
       "(0.0408, 0.0585]             78  \n",
       "(0.0585, 0.0749]             79  \n",
       "(0.0749, 0.0845]             80  \n",
       "(0.0845, 0.137]              81  \n",
       "(0.137, 0.147]               82  \n",
       "(0.147, 0.777]               83  \n",
       "(0.777, 0.806]               84  \n",
       "(0.806, 0.836]               85  \n",
       "(0.836, 0.851]               86  \n",
       "(0.851, 0.874]               87  \n",
       "(0.874, 0.895]               88  \n",
       "(0.895, 0.906]               89  \n",
       "(0.906, 0.919]               90  \n",
       "(0.919, 0.938]               91  \n",
       "(0.938, 0.953]               92  \n",
       "(0.953, 0.964]               93  \n",
       "(0.964, 0.974]               94  \n",
       "(0.974, 0.977]               95  \n",
       "(0.977, 0.981]               96  \n",
       "(0.981, 0.988]               97  \n",
       "(0.988, 0.992]               98  \n",
       "(0.992, 0.995]               99  \n",
       "(0.995, 0.999]              100  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = CV_Ensemble_1.predict_proba(train, use_cut_offs=False)\n",
    "y_true = train['Class']\n",
    "\n",
    "compute_cut_off(y_pred=y_pred, y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7eedba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:48.628511Z",
     "iopub.status.busy": "2023-08-02T14:52:48.627057Z",
     "iopub.status.idle": "2023-08-02T14:52:48.711338Z",
     "shell.execute_reply": "2023-08-02T14:52:48.710325Z"
    },
    "papermill": {
     "duration": 0.097186,
     "end_time": "2023-08-02T14:52:48.713821",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.616635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.9\n",
      "Before\n",
      "0.04835704356732542\n",
      "After\n",
      "0.035423191502991724\n"
     ]
    }
   ],
   "source": [
    "CV_Ensemble_1.set_cut_offs(lower=0.01,upper=0.9) # 95 perc 0.892 and 52% 0.11\n",
    "\n",
    "print(CV_Ensemble_1.cut_off_lower)\n",
    "print(CV_Ensemble_1.cut_off_upper)\n",
    " \n",
    "y_pred_rf_train = CV_Ensemble_1.predict_proba(train, use_cut_offs=True)\n",
    "\n",
    "y_pred_rf_train\n",
    "\n",
    "print('Before')\n",
    "print(balanced_logloss_np(y_pred=y_pred.values,y_true=y_true.values))\n",
    "print('After')\n",
    "print(balanced_logloss_np(y_pred=y_pred_rf_train,y_true=y_true.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91eed247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:48.734694Z",
     "iopub.status.busy": "2023-08-02T14:52:48.734213Z",
     "iopub.status.idle": "2023-08-02T14:52:48.751091Z",
     "shell.execute_reply": "2023-08-02T14:52:48.749806Z"
    },
    "papermill": {
     "duration": 0.030347,
     "end_time": "2023-08-02T14:52:48.754027",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.723680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_Ensemble_1.save(save_path='/kaggle/working/XGB/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c77efe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:52:48.774013Z",
     "iopub.status.busy": "2023-08-02T14:52:48.773478Z",
     "iopub.status.idle": "2023-08-02T14:52:48.809497Z",
     "shell.execute_reply": "2023-08-02T14:52:48.808560Z"
    },
    "papermill": {
     "duration": 0.049265,
     "end_time": "2023-08-02T14:52:48.812209",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.762944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Full\n",
    "\n",
    "_ = joblib.dump(value=CV_Ensemble_1, filename='Full_Model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10843c",
   "metadata": {
    "papermill": {
     "duration": 0.008621,
     "end_time": "2023-08-02T14:52:48.830697",
     "exception": false,
     "start_time": "2023-08-02T14:52:48.822076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.483407,
   "end_time": "2023-08-02T14:52:52.158941",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-02T14:52:18.675534",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
